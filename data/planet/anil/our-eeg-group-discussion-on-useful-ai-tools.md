---
title: Our EEG group discussion on 'useful' AI tools
description: EEG group discusses useful AI tools and emerging techniques in productivity
  and research.
url: https://anil.recoil.org/notes/the-state-of-ai-tools
date: 2025-03-07T00:00:00-00:00
preview_image:
authors:
- Anil Madhavapeddy
source:
ignore: true
---

<p><a href="https://svr-sk818-web.cl.cam.ac.uk/keshav/wiki/index.php/Main_Page" class="contact">Srinivasan Keshav</a> organised this week's <a href="https://www.cst.cam.ac.uk/research/eeg">EEG</a> group <a href="https://www.cst.cam.ac.uk/seminars/list/229027">discussion</a> on what AI tools we use for our daily work.  I was immediately struck by how <em>few</em> tools there are that are actually making us more productive, so I jotted down notes as the discussion was going on.</p>
<ul>
<li>Personally, the only tool I've found that's (only just recently) making me more productive is agentic coding, which I <a href="https://anil.recoil.org/notes/claude-copilot-sandbox">wrote about a few days ago</a>.  Since then, I've been mildly obsessively forking off ideas I've wanted to try for years (like converting RFCs to OCaml code) and greatly enjoying myself. <a href="https://patrick.sirref.org" class="contact">Patrick Ferris</a> and I have been looking for how to do this more ethically, and the best I ran across was the <a href="https://www.ibm.com/impact/ai-ethics">IBM AI ethics</a> guidance and their <a href="https://github.com/ibm-granite/granite-code-models">granite models</a>, but not much else. Any pointers to other models that don't violate open source licensing norms would be gratefully accepted; I'm using Claude 3.7 here, but don't feel great doing so!</li>
<li><a href="https://svr-sk818-web.cl.cam.ac.uk/keshav/wiki/index.php/Main_Page" class="contact">Srinivasan Keshav</a> described his use of <a href="https://fathom.video/">Fathom</a> for note-taking, and (having been on the receiving end) can confirm it does a very good transcription job.</li>
<li><a href="mailto:jon.crowcroft@cl.cam.ac.uk" class="contact">Jon Crowcroft</a> has a local <a href="https://stabledifffusion.com/">Stable Diffusion</a> image generator to help create local content for presentations/etc, but the setup broke when going from macOS 13 to 15 (Sequoia). Apple seem to have changed something in <a href="https://developer.apple.com/metal/">Metal</a> so the existing HuggingFace installation (mostly <a href="https://developer.apple.com/metal/pytorch/">pyTorch-metal</a> and the <a href="https://developer.apple.com/metal/tensorflow-plugin/">Tensorflow MPS</a> backend) were out of date with the system Metal libraries. Package management for these tightly integrated hardware/software inference systems is pretty bad right now (<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">nvidia-container-toolkit</a> is another bag of hacks for containerised applications).</li>
</ul>
<p>Then there's a long list of things that people <em>aren't</em> using because they suck. LLM-driven searches are pretty inaccurate, as many people noted; I use <a href="https://kagi.com">Kagi</a> but only because I love their AI-filtered search results, not because of their assistant!. I've turned off Apple Intelligence on all my devices, not because of privacy concerns, but because it's just utter crap -- the summaries are actually <a href="https://www.bbc.co.uk/news/articles/cq5ggew08eyo">incorrect</a> half the time. I find the autocorrect features similarly distracting and wrong most of the time, and normal spellcheckers do a better job in practise.</p>
<h2>Where's this going?</h2>
<p>Our discussion then into developing news of emerging tools and techniques, since the field overall is just moving incredibly fast. Two things I've been reading this week are:</p>
<ul>
<li>With <a href="https://awards.acm.org/about/2024-turing">RL winning the Turing award</a> this week, some folks investigated whether lightweight open-weight models could reach the performance of advanced heavy frontier models in terms of deductive reasoning. They applied RL to train an LLM for the <a href="https://openpipe.ai/blog/using-grpo-to-beat-o1-o3-mini-and-r1-on-temporal-clue">game of temporal clue</a>, and their post describes many neat tricks (including the use of <a href="https://developers.google.com/optimization/cp/cp_solver">CP-SAT</a> to generate difficult-but-solvable game scenarios). They applied <a href="https://arxiv.org/abs/2402.03300">GRPO</a> (as made famous by <a href="https://anil.recoil.org/notes/deepseek-r1-advances">DeepSeek</a>) to do the RL loop of solving puzzles via model responses, grading groups of responses, and fine tuning the model using clipped policy gradients derived from these group estimates. Their results <a href="https://openpipe.ai/blog/using-grpo-to-beat-o1-o3-mini-and-r1-on-temporal-clue">were impressive</a> and reached frontier-model performance using Qwen 14B!</li>
<li>And for something completely different, another team released their <a href="https://google-research.github.io/self-organising-systems/difflogic-ca/">Differentiable Logic Cellular Automata</a> paper which describes how to go from the <a href="https://en.wikipedia.org/wiki/Conway's_Game_of_Life">Game of Life</a> to full pattern generation using learned recurrent circuits. This one should really be read in its entirity to appreciate how incredible it might become in the future, as it would allow us to generate distributed systems that can build a very complex end-goal pattern by following a set of simple rules. <a href="https://coomeslab.org" class="contact">David A Coomes</a> pointed out to me recently that the question of <a href="https://www.wired.com/story/mystery-solved-how-plant-cells-know-when-to-stop-growing/">why cells stop growing</a> has only very recently been understood in traditional biology, and yet here we are applying ML to the case.</li>
<li><a href="https://mistral.ai/fr/news/mistral-ocr">Mistral OCR</a> came out today and seems to be the state of the art in multi-modally breaking down documents into a consistent linear structure. Their results show that they can break down complex PDFs in multiple languages into seemingly clean HTML with semantic structure (such as tables, equations, figures and so on). I've only just finished running <a href="https://anil.recoil.org/projects/ce">millions of papers</a> through <a href="https://grobid.readthedocs.io/en/latest/">Grobid</a>, so this is next on the queue to try out...</li>
</ul>
<p>So, I guess the TL;DR of our discussion was that current AI tools are the first generation, but we're heading rather rapidly into new frontiers of discovery, so there's only going to be more of them coming up...</p>

