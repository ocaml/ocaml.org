---
title: Benchmarking OCaml projects with current-bench
description: "Regular CI systems are optimised for workloads that do not require stable
  performance over time. This makes them unsuitable for running\u2026"
url: https://tarides.com/blog/2021-08-26-benchmarking-ocaml-projects-with-current-bench
date: 2021-08-26T00:00:00-00:00
preview_image: https://tarides.com/static/2bd2e5940bdb329b93e236f44dd37e01/dfe86/current-bench-camel.jpg
authors:
- Tarides
source:
---

<p>Regular CI systems are optimised for workloads that do not require stable performance over time. This makes them unsuitable for running performance benchmarks.</p>
<p><a href="https://github.com/ocurrent/current-bench"><code>current-bench</code></a> provides a predictable environment for performance benchmarks and a UI for analysing results over time. Similar to a CI system, it runs on pull requests and branches which allows performance to be analysed and compared.  It can currently be enabled as an app on GitHub repositories with zero configuration. Several public repositories are running<code>current-bench</code>, including <a href="https://github.com/mirage/irmin">Irmin</a> and <a href="https://github.com/ocaml/dune">Dune</a>. We plan to enable it on more projects in the future.</p>
<p>In this article, we give a technical overview of <code>current-bench</code>, showing how results are collected and analysed, requirements for using it and how we built the infrastructure for stable benchmarks. We also describe future work that would allow more OCaml projects to run <code>current-bench</code>.</p>
<h2 style="position:relative;"><a href="https://tarides.com/feed.xml#introduction" aria-label="introduction permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h2>
<p>For performance critical software, we must run benchmarks to ensure that there's no regression. Running benchmarks before the user submits their pull request is tedious, and since every user might have a different machine, you can't be sure if the benchmarks performed actually improved or regressed performance.</p>
<p>Our <code>current-bench</code> aims to solve this problem by providing a stable benchmarking platform that runs every time the user submits a pull request and compares the result to the benchmarks on the main branch. As <code>current-bench</code> is zero-configuration, users can enroll their repository to run benchmarks with ease. This <code>current-bench</code> has helped projects ensure that regression doesn't happen, so you can merge code with more confidence.</p>
<h2 style="position:relative;"><a href="https://tarides.com/feed.xml#architecture" aria-label="architecture permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Architecture</h2>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; ">
      <a href="https://tarides.com/static/2924487e1eab06d8ffdb4bc2e3cdbbd1/37523/current-bench-arch.png" class="gatsby-resp-image-link" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 75.29411764705883%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsTAAALEwEAmpwYAAABm0lEQVR42sWSzStEYRTGf66Z6874mMbXSLPSCNkoMhZyIyPjo0aZMEoZM0UZFhbsRkqWUgoxRZSIha0FpVjg37GwcfXqTF2U8bFw6nQ+et/nfZ5zXvhsOmAADn5jsa6NzqH2jd5IcD0cC2136LpeBwSBcsApD+iS57aZyIm1PHP5sjp/ZaWGz5+CNWO1gAv8LgFtBPxAAaDlBIz3Z25TI8f387HTx8TgwXVVWV0L0ACFPsAD1ANVApiXEzAajeaD6YBmp2VZecJKyXbLERV932KXw7JsKkS2/lcgh2y7FCixLcYttVtqdaZI6i8fzQeqZeNqhoXiPumVAcUSm2RMrncIaobpdFpTMRAIFHi9Xo8AeISJIUy8tlx5pcze+I58u9t7mi03RJEw4227TIR3E8nBw6PpyNF2vG9/fzS0qaRhmuoXvF0wZG6azbOA2jupKs5GLs5Wkg/WWurueWn8xor3HyRVv80fdcmlVqBZ/qRuc+PDHxWGoZ2eeO/e4tRAZm4ynFkY696qtSsQdk7+zdSGTTPtyHp2FD+xVxMqWejaiiYDAAAAAElFTkSuQmCC'); background-size: cover; display: block;"></span>
  <img src="https://tarides.com/static/2924487e1eab06d8ffdb4bc2e3cdbbd1/c5bb3/current-bench-arch.png" class="gatsby-resp-image-image" alt="Figure 1: Current bench architecture" title="" srcset="/static/2924487e1eab06d8ffdb4bc2e3cdbbd1/04472/current-bench-arch.png 170w,
/static/2924487e1eab06d8ffdb4bc2e3cdbbd1/9f933/current-bench-arch.png 340w,
/static/2924487e1eab06d8ffdb4bc2e3cdbbd1/c5bb3/current-bench-arch.png 680w,
/static/2924487e1eab06d8ffdb4bc2e3cdbbd1/37523/current-bench-arch.png 720w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<h3 style="position:relative;"><a href="https://tarides.com/feed.xml#benchmarking-pipeline" aria-label="benchmarking pipeline permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Benchmarking Pipeline</h3>
<p>As shown in Figure 1 (above), the benchmarking infrastructure uses <code>ocurrent</code><sup><a href="https://icfp20.sigplan.org/details/ocaml-2020-papers/6/OCaml-CI-A-Zero-Configuration-CI">1</a></sup>, an embedded Domain Specific Language to write a pipeline. The <code>ocurrent</code> command computes the build incrementally and helps with static analysis. Whenever a pull request is opened on a repository monitored by <code>current-bench</code>, a <code>POST</code> request is sent to the server running the pipeline. The pipeline fetches the head commit on the pull request and uses Docker to compile the code, and then it runs the <code>make bench</code> command inside the generated Docker image.</p>
<p>The pipeline runs on a single node, and the process is pinned to a single core to ensure there's no contention of resources when running the benchmarks. Once finished, the raw JSON result is stored in a <code>Postgres</code> database, which the frontend can query using a <code>GraphQL</code> API, as shown in Figure 2 below.</p>
<p><span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 680px; ">
      <a href="https://tarides.com/static/766e96b985de064519c776b0c59635b7/d0c2f/current-bench-ui.png" class="gatsby-resp-image-link" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 63.52941176470588%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACQklEQVR42oVS227aQBD1P4dL2vdKfexH5DE/wCVVlTwgJWqIwARDDFFNK/DaOMZre+1d26eaIdC+VB3paHauqzkz1u23rxiNRri/v8fd3S0uu120Wy102210Ox186Hb/jU4H7YsWPl5eon1xgS+fP8H69TJGmcU4JCmklFguFnBdF57nwdtssNvtGNvt9oyTvXZdPE9mmNk25rNnfH94gOXaD/j56mLnC8RxDKUUjDH4n9R1A601I89z9r2u17Ds+QuiWMJojSzLIILgnHAsrLHxNgiEgPB9HA4H1FXFEwghsN+HiKKIc5fLJayZs0ZeGJRleWwYhojiGKWpoUrDyPISmSohM8WgWF5opHmBJM3ZR+IsFrCmtgNtGlSVQZpmSKTBdkecSpiqhjYV9tEbfBFCFSVKbeCLACIIIbOccyhelBrO3IFlTyc8Vl1XkDLDagVsNjXqqgaaBg2jRhiG8H3/TENZanjeD+a7UIrHt20b1mQyQVXVXEhBLtxtefyTUCyK3jgeBAF8IfgiTkK8JzLF3HFgPT4+8qZIqqriscLowNwQf3GqkDCHBTeWaYb9WwKZFcx9LBUvtWkAhxo+PY25EdCw5hGKAlob/oiWReOdTolsbfT7yRiOkY+E7tcaj8ccpIJj8XHb1JSh1PnNEyjFIJtySSuV/zmb6XR65olAhCdJwkdOPNHdkT5xSh9TnPykT7lUu1qtYF1dXaHX62E4HKLf7+Pm5oZ1v9dj3XvXZA8HAwwGA37/7ac31V1fX+M360e9eIw2X7cAAAAASUVORK5CYII='); background-size: cover; display: block;"></span>
  <img src="https://tarides.com/static/766e96b985de064519c776b0c59635b7/c5bb3/current-bench-ui.png" class="gatsby-resp-image-image" alt="Figure 2: Current bench UI" title="" srcset="/static/766e96b985de064519c776b0c59635b7/04472/current-bench-ui.png 170w,
/static/766e96b985de064519c776b0c59635b7/9f933/current-bench-ui.png 340w,
/static/766e96b985de064519c776b0c59635b7/c5bb3/current-bench-ui.png 680w,
/static/766e96b985de064519c776b0c59635b7/b12f7/current-bench-ui.png 1020w,
/static/766e96b985de064519c776b0c59635b7/b5a09/current-bench-ui.png 1360w,
/static/766e96b985de064519c776b0c59635b7/d0c2f/current-bench-ui.png 1362w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p>The frontend supports historical navigation and provides comparison with the default branch. It allows users to select a pull request of which they want to see the graphs. The graphs display the individual result of the head commit and the comparison with the commits on the default branch. The frontend permits users to select the historical interval when they want to compare benchmarks, and it also shows the standard deviation.  Once the benchmarks have run successfully, the pipeline sets the pull request status to the frontend URL. Then the user can look at the graphs.</p>
<h3 style="position:relative;"><a href="https://tarides.com/feed.xml#hardware-optimisation" aria-label="hardware optimisation permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hardware Optimisation</h3>
<p>Our <code>current-bench</code> uses the hardware optimisations developed for OCaml multicore compiler benchmarks <a href="https://github.com/ocaml-bench/ocaml_bench_scripts#notes-on-hardware-and-os-settings-for-linux-benchmarking">(presented at ICFP OCaml Workshop 2019)</a> with a few modifications to allow the benchmarks to run inside Docker containers. To get stable performance, we configured the kernel to isolate some of the CPU cores. Linux then avoids scheduling other user processes automatically. We also disabled IRQ handling and power saving.</p>
<p>The container that runs the benchmark is pinned to one of the isolated cores. Since I/O operations can make the benchmarks less stable, we use an in-memory <code>tmpfs</code> partition in <code>/dev/shm</code> for all storage. For NUMA enabled systems, we configure this partition to be allocated on the NUMA node of the isolated core. The pipeline disables ASLR inside the container automatically, which is normally blocked by the default Docker seccomp profile, so we have modified the profile to allow the <code>personality(2)</code> syscall.</p>
<h2 style="position:relative;"><a href="https://tarides.com/feed.xml#enrolling-a-repository" aria-label="enrolling a repository permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enrolling a repository</h2>
<p>To enroll a repository, you need to ensure the following:</p>
<ul>
<li>Enable the <a href="https://github.com/marketplace/ocaml-benchmarks">ocaml-benchmarks</a> GitHub app for your repository.</li>
<li>The repository needs a <code>bench</code> Makefile target. This is triggered from the <code>current-bench</code> pipeline.</li>
<li>The output of the <code>make bench</code> target is JSON, which can be parsed by the pipeline and displayed by the frontend.</li>
</ul>
<h2 style="position:relative;"><a href="https://tarides.com/feed.xml#future-work" aria-label="future work permalink" class="anchor before"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewbox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Future work</h2>
<p>Anyone who wants to roll out a continuous, zero-configured benchmarking infrastructure can set up the current-bench infrastructure. In the future, we want to scale <code>current-bench</code> by isolating cores on multiple machines and adding a scheduler to ensure that benchmarks use only one core at a time per machine. We plan to add support for different benchmarking libraries that repositories can use&mdash;for example, we currently support repositories using <code>bechamel</code>.  We also aim to make the adoption of <code>current-bench</code> easier by adding a conversion library that can convert any benchmark output into output parseable by <code>current-bench</code>. We intend to add support for <code>quick</code> and <code>slow</code> benchmarks, which would allow users to have faster feedback loops on pull requests while ensuring they can still run more extensive, time consuming benchmarks to see the performance.</p>
<p>Thank you for reading! You can check out the implementation for <code>current-bench</code> <a href="https://github.com/ocurrent/current-bench">here</a>!</p>
