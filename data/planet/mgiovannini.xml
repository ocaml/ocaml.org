<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>http://www.blogger.com/feeds/5888658295182480819/posts/default</id><title type="text">mgiovannini</title><updated>2023-06-07T05:45:50-00:00</updated><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/10/how-to-write-simple-web-application.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">This post might seem to be in apparent contradiction: Ocamlnet is a large, very opinionated framework for network programming that solves most, if not all, those infrastructure issues that need to be taken care of when writing a networked, distributed, fault-tolerant server, from process management to string decoding and including protocol parsing and building. The fact is that Ocamlnet is not </content><id>https://alaska-kamtchatka.blogspot.com/2012/10/how-to-write-simple-web-application.html</id><title type="text">How to Write a Simple Web Application Using Ocamlnet</title><updated>2012-10-25T14:58:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/08/merge-right.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">The so-called master-transaction update is one of the, if not the defining algorithms of the discipline formerly known as &amp;quot;data processing&amp;quot;. Given two sorted files of records with increasing keys, the process applies each record in the transaction file to each record of the the master file and outputs the result, if any, to the updated master file in one pass over each input. The same algorithm </content><id>https://alaska-kamtchatka.blogspot.com/2012/08/merge-right.html</id><title type="text">Merge Right</title><updated>2012-08-07T00:15:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/08/a-helping-phantom-hand.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">You don't have to be writing an interpreter or some other kind of abstract code to profit from some phantom types. Suppose you have two or more functions that work by &amp;quot;cooking&amp;quot; a simple value (a float, say) with a lengthy computation before proceeding:


let sun_geometric_longitude j =
  let je = to_jcen (to_jde j) in
  (* &amp;hellip; computation with je &amp;hellip; *)

let sun_apparent_longitude j =
  let je = </content><id>https://alaska-kamtchatka.blogspot.com/2012/08/a-helping-phantom-hand.html</id><title type="text">A Helping Phantom Hand</title><updated>2012-08-02T13:59:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/07/theorems-for-free-monad-edition.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">This is for the record, since the derivations took me a while and I'd rather not lose them.

A functor is the signature:


module type FUNCTOR = sig
  type 'a t
  val fmap : ('a -&amp;gt; 'b) -&amp;gt; ('a t -&amp;gt; 'b t)
end


satisfying the following laws:


Identity:    fmap id      &amp;equiv; id
Composition: fmap (f &amp;#8728; g) &amp;equiv; fmap f &amp;#8728; fmap g


An applicative structure or idiom is the signature:


module type APPLICATIVE = </content><id>https://alaska-kamtchatka.blogspot.com/2012/07/theorems-for-free-monad-edition.html</id><title type="text">Theorems for Free: The Monad Edition</title><updated>2012-07-19T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/07/odd-lemma.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">While proving that every monad is an applicative functor, I extracted the following derivation as a lemma:


  fmap f &amp;#8728; (&amp;lambda;h. fmap h x)
&amp;equiv; { defn. &amp;#8728;, &amp;beta;-reduction }
  &amp;lambda;g. fmap f (fmap g x)
&amp;equiv; { defn. &amp;#8728; }
  &amp;lambda;g. (fmap f &amp;#8728; fmap g) x
&amp;equiv; { Functor }
  &amp;lambda;g. fmap (f &amp;#8728; g) x
&amp;equiv; { abstract f &amp;#8728; g }
  &amp;lambda;g. (&amp;lambda;h. fmap h x) (f &amp;#8728; g)
&amp;equiv; { defn. &amp;#8728;, &amp;eta;-contraction }
  (&amp;lambda;h. fmap h x) &amp;#8728; (f &amp;#8728;)


for all f, x. This is the Yoneda</content><id>https://alaska-kamtchatka.blogspot.com/2012/07/odd-lemma.html</id><title type="text">An Odd Lemma</title><updated>2012-07-17T17:36:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/07/minor-branch-off-braun-trees.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Revisiting the post on Braun Trees I noticed that, while pedagogical, the implementation of the root replacement operation rep can be streamlined a bit. By inlining the mutually recursive siftdown, specializing on the matches and adding guards, the result is as follows:


let rec rep compare e = function
| N (_, (N (el, _, _) as l), E)
  when compare el e  &amp;lt; 0 -&amp;gt;
  N (el, rep compare e l, E)
| N </content><id>https://alaska-kamtchatka.blogspot.com/2012/07/minor-branch-off-braun-trees.html</id><title type="text">A minor branch off Braun Trees</title><updated>2012-07-12T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/07/existential-crisis.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">In a long discussion at LtU, user Jules Jacobs advances a use-case that for him would have been difficult to solve in a statically-typed language. I focus on his first two points:



A data structure that is a container of T plus a function on T's. I would have needed existential types to hide the T, which I don't get in many languages.
A couple of functions that take heterogeneous list of items </content><id>https://alaska-kamtchatka.blogspot.com/2012/07/existential-crisis.html</id><title type="text">Existential Crisis</title><updated>2012-07-09T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/07/assessing-abstractions.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Back to OCaml! Catching up with StackOverflow's OCaml questions, I found an interesting one about private type abbreviations in module signatures. One thing in that conversation that struck me as odd was the assertion that the compiler optimizes single-constructor variants, thereby subsuming the semantics of Haskell's all three declarators, data, type and newtype, into one. Definitive proof would</content><id>https://alaska-kamtchatka.blogspot.com/2012/07/assessing-abstractions.html</id><title type="text">Assessing Abstractions</title><updated>2012-07-02T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-5-final.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">The code has now the proper shape to carry out optimizations to their logical consequences, to the point that I question the wisdom in some of the previous transformations. It is true that in compiler construction some passes introduce constructs only for latter passes to eliminate them, in the hope of an overall simplification. In this case the starting point will be the elimination of the </content><id>https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-5-final.html</id><title type="text">2D Interpolation, Part 5: Final Optimizations</title><updated>2012-06-29T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-4-argb.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">After linearizing all array accesses, interpolating ARGB values is easy from the algorithmic side of things; so easy things first. I'll handle the pixel interpolation proper by abstracting them away in their own little functions. Processing an ARGB source array is just a matter of changing the variable declarations:


final int[] srcpix = {
0xff0051ff, 0xff00fffb, 0xff9cff00, 0xff0051ff,
</content><id>https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-4-argb.html</id><title type="text">2D Interpolation, Part 4: ARGB Interpolation</title><updated>2012-06-28T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-3-linear-array.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Last time I've hoisted all accesses to the source array. This opens the door to being able to process linear arrays representing a matrix in row-major order by stenciling. Not only that, but I was able to completely eliminate the need to have a bordered array on input by explicitly replicating elements as needed. The first step is to use a row buffer into which to copy the elements to be </content><id>https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-3-linear-array.html</id><title type="text">2D Interpolation, Part 3: Linear Array Accesses</title><updated>2012-06-27T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-2-minimizing.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Last time I massaged the interpolator to avoid computing every time the linear transformation from destination space to source space, using only integer variables. With that rewriting, it is time to avoid referencing source values more than is needed. First thing we do, let's name all elements:


void interp0() {
  int offset = 0;
  int yn = 0;
  int yi = 1;
  for (int i = 0; i &amp;lt; height; i++) {
</content><id>https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-2-minimizing.html</id><title type="text">2D Interpolation, Part 2: Minimizing Array Accesses</title><updated>2012-06-26T13:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-1-digital.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">To my Planet OCaml readers, I apologize for veering into Java. I've been playing with Processing of lately, because it's far easier to prototype silly, simple animations (fractals! Fractals everywhere!) in it than by using OCamlSDL, say. Last time I showed a basic 2D interpolator; now it's time to start massaging it into shape. Let's recall the original code:


void interp0() {
  final float dy =</content><id>https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-1-digital.html</id><title type="text">2D Interpolation, Part 1: The Digital Differential Analyzer</title><updated>2012-06-25T15:00:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-0-groundwork.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">(First of a series) My process for going from a textbook implementation of an algorithm to an efficient production-grade version of it is to methodically apply meaning-preserving transformations that make the code progressively tighter. In this case I'll massage a na&amp;iuml;ve 2D interpolator that selectively uses nearest-neighbor, bilinear and bicubic interpolation. I started by studying a basic </content><id>https://alaska-kamtchatka.blogspot.com/2012/06/2d-interpolation-part-0-groundwork.html</id><title type="text">2D Interpolation, Part 0: The Groundwork</title><updated>2012-06-22T17:51:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/02/for-right-hand.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Useful generic functions are usually the result of composing useful generic functions; the fact that these are easy to write is, however, not an excuse for not having them in a rich prelude. Given a total function for splitting a list at a given point:
let rec split_at n = function
| []            -&amp;gt; [], []
| l when n == 0 -&amp;gt; [], l
| x :: xs       -&amp;gt;
  let l, r = split_at (pred n) xs in
  x :: l,</content><id>https://alaska-kamtchatka.blogspot.com/2012/02/for-right-hand.html</id><title type="text">For the Right Hand</title><updated>2012-02-22T13:43:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/01/file-sharing-on-spot.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">(now with highlighting!) Last time I complained that I couldn't find an easy way to share a source code archive that didn't involve signing up for a service I didn't care for. Blogging platforms only make easy to attach images to posts, so why not pack a file as a PNG? Enter PNGPack. I tried finding OCaml bindings to libpng; after a disheartening exploration I realized that Java is (for me at </content><id>https://alaska-kamtchatka.blogspot.com/2012/01/file-sharing-on-spot.html</id><title type="text">File Sharing on the Spot</title><updated>2012-01-12T17:37:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/01/eighteen-million-noises.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Update: Here is the PNGPack source-code archive:
Per second. Yes, it's benchmark time. I pitted Prof. Perlin's original implementation against Stefan Gustavson's, and the results are in! I ran two sets of benchmarks, one in Java and the other in OCaml. In both cases I compared three versions of Simplex Noise: Perlin's pipelined 3D Noise, and Gustavson's 2D Noise and 3D Noise:
noisep: Perlin's 3D </content><id>https://alaska-kamtchatka.blogspot.com/2012/01/eighteen-million-noises.html</id><title type="text">Eighteen Million Noises</title><updated>2012-01-11T13:02:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/01/putting-noise-to-test.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">So how do you use Perlin's Simplex Noise? By using the GIF encoder, of course! I generated the test image shown in the last post:

with a minimal application of both modules in test.ml (source code follows). For a visually richer but not much more complicated example, I also tried replicating I&amp;ntilde;igo Qu&amp;iacute;lez's turbulent textures in fbm.ml. The animation traces a tiny loop in noise space so that it </content><id>https://alaska-kamtchatka.blogspot.com/2012/01/putting-noise-to-test.html</id><title type="text">Putting Noise to the Test</title><updated>2012-01-09T14:22:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2012/01/perlins-simplex-noise.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Graphics pioneer Ken Perlin is well-known for his work on procedural generation of textures. Recently he rewrote his classic Noise algorithm to reduce the complexity of generating pseudorandom gradients in higher dimensions by transforming a problem on N-cells to one on N-simplices. I couldn't find on his NYU home page a write-up by his own hand; apparently the only implementation exists in his </content><id>https://alaska-kamtchatka.blogspot.com/2012/01/perlins-simplex-noise.html</id><title type="text">Perlin's Simplex Noise</title><updated>2012-01-06T16:39:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2011/12/one-by-four-by-nine.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">
The four nines puzzle asks which positive numbers can be obtained from arithmetic expressions involving four &amp;quot;9&amp;quot; digits and an assortment of operations, minimally &amp;quot;+&amp;quot;, &amp;quot;-&amp;quot; (binary and unary), &amp;quot;&amp;times;&amp;quot; and &amp;quot;/&amp;quot;, also frequently &amp;quot;&amp;radic;&amp;quot; and sometimes &amp;quot;!&amp;quot; (factorial). I'll show how to find them by brute force. In this case, I'll forgo using factorials; this means that not every number under 100 can be so </content><id>https://alaska-kamtchatka.blogspot.com/2011/12/one-by-four-by-nine.html</id><title type="text">(One by) Four by Nine</title><updated>2011-12-30T18:50:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2011/12/voses-alias-method.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">This is a note regarding the implementation of Vose's Method to construct the alias tables for non-uniform discrete probability sampling presented by Keith Schwartz (as of 2011-12-29). Mr. Schwartz otherwise very informative write-up contains an error in the presentation of the Method. Step 5 of the algorithm fails if the Small list is nonempty but the Large list is. This can happen either:
if </content><id>https://alaska-kamtchatka.blogspot.com/2011/12/voses-alias-method.html</id><title type="text">Vose's Alias Method</title><updated>2011-12-29T17:12:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2011/12/better-gauss-error-function.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">If you do statistics you know of erf and erfc; if you work in OCaml you surely miss them. It is not very difficult to port the canonical implementation given by Numerical Recipes (which I won't show and not just for licensing reasons); if you Google for a coefficient you'll see that this approximation is, indeed, ubiquitous. There exists a better approximation in the literature, one that is more </content><id>https://alaska-kamtchatka.blogspot.com/2011/12/better-gauss-error-function.html</id><title type="text">A Better (Gauss) Error Function</title><updated>2011-12-21T14:53:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2011/11/brainfuck-in-java.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">
(I don't feel like writing a punning title.) Last time I showed how the use of functors allows for modular and type-safe specification of semantics. I wrote I can't imagine this flexibility in object-oriented languages like Java or Python; fighting words for which I was justly taken to task. Here's my penance: a morally equivalent reimplementation in Java of the Brainfuck interpreter. The </content><id>https://alaska-kamtchatka.blogspot.com/2011/11/brainfuck-in-java.html</id><title type="text">Brainfuck in Java</title><updated>2011-11-17T21:45:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2011/11/modular-semantics-for-brainfuck.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">
The problem with Brainfuck is that its semantics are given by its different implementations but not all its implementations agree so that writing an interpreter is straightforward but writing portable Brainfuck programs is not. OCaml functors allows playing with pluggable semantics in a way that would be very difficult laborious with other languages. I can't imagine this flexibility in </content><id>https://alaska-kamtchatka.blogspot.com/2011/11/modular-semantics-for-brainfuck.html</id><title type="text">Modular Semantics for Brainfuck</title><updated>2011-11-11T14:05:00-00:00</updated><author><name>Matías Giovannini</name></author></entry><entry><link href="https://alaska-kamtchatka.blogspot.com/2011/10/first-principles-gif-encoder.html" rel="alternate"/><contributor><uri>http://www.blogger.com/feeds/5888658295182480819/posts/default</uri><name>mgiovannini</name></contributor><content type="html">Also, quasicrystals. Have you ever found yourself wanting to do generated animations but didn't know how to visualize them? Since I couldn't find a self-contained GIF encoder, I made myself one. Even though it is not fast, I think its 220 lines are clear enough to be a good reference implementation to build upon. The encoder conforms to the following interface:
type palette
val palette : ?</content><id>https://alaska-kamtchatka.blogspot.com/2011/10/first-principles-gif-encoder.html</id><title type="text">A First-Principles GIF Encoder</title><updated>2011-10-28T19:58:00-00:00</updated><author><name>Matías Giovannini</name></author></entry></feed>