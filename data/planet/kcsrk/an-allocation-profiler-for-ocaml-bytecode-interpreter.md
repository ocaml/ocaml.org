---
title: An Allocation Profiler for OCaml Bytecode Interpreter
description:
url: https://kcsrk.info/ocaml/profiling/2015/09/23/bytecode-allocation-profiler/
date: 2015-09-23T09:51:30-00:00
preview_image:
authors:
- KC Sivaramakrishnan
source:
---

<p>This post describes a simple flat allocation profiler for OCaml 4.02 bytecode
interpreter.</p>



<p>OCaml is a strongly typed functional language with automatic memory management.
Automatic memory management alleviates the need to manually deal with memory
memory management, and by construction, avoids a large class of bugs. However,
abstractions are not free in OCaml. Unlike <a href="http://mlton.org/">MLton</a>, a
whole-program optimizing Standard ML compiler, which I used to hack on in <a href="http://multimlton.cs.purdue.edu/mML/Welcome.html">an
earlier life</a>, in OCaml, one
needs to be particularly aware of the cost of introducing abstractions such as
higher-order functions and modules. This is often at odds with desirable
programming patterns one tends to embrace in a higher-order modular functional
language. Writing performance sensitive code in OCaml remains a skill that is
acquired gradually through experience.</p>

<p>There are of course, excellent
<a href="https://janestreet.github.io/ocaml-perf-notes.html">resources</a>
<a href="https://ocaml.org/learn/tutorials/performance_and_profiling.html">available</a>
to understand the performance implications of OCaml abstractions. However,
often times, I simply need a way to profile and uncover performance bottlenecks
in my program, before I can apply any targeted optimizations. Profiling along
the following three axes are particularly useful: <em>time</em>, <em>counts</em> and
<em>allocations</em>. OCaml has <a href="http://caml.inria.fr/pub/docs/manual-ocaml/profil.html">good support for two of
these</a>. While <code class="language-plaintext highlighter-rouge">ocamlcp</code>
with <code class="language-plaintext highlighter-rouge">ocamlprof</code> gives you count profile, one can use the standard Unix
profiler <code class="language-plaintext highlighter-rouge">gprof</code> for time profiling. However, these do not necessarily help
with identifying the cost of abstractions, for which one needs an allocation
profiler<sup role="doc-noteref"><a href="https://kcsrk.info/atom-ocaml.xml#fn:1" class="footnote" rel="footnote">1</a></sup>.</p>

<h1>The state of allocation profiling in OCaml</h1>

<p>While allocation profiler is not part of the standard OCaml distribution,
several alternatives do exist. <a href="http://memprof.typerex.org/">Memprof</a> from
<a href="http://www.ocamlpro.com/">OCamlPro</a> provides <em>&ldquo;non-intrusive memory profiler
for OCaml applications&rdquo;</em>, with a simple online version and a commercial version
with fine-grained tracing. Mark Shinwell has an <a href="https://github.com/mshinwell/ocaml/tree/4.02-allocation-profiling">allocation profiler for OCaml
4.02</a> native
code programs generated by <code class="language-plaintext highlighter-rouge">ocamlopt</code>. Unfortunately, neither of these options
were suitable for me as the <a href="https://github.com/ocamllabs/ocaml-multicore">Multicore
OCaml</a> currently only supports
bytecode compilation, and has a
<a href="http://www.lpw25.net/ocaml2014-abs.pdf">markedly</a>
<a href="http://www.cl.cam.ac.uk/~sd601/papers/multicore_slides.pdf">different</a>
<a href="https://www.youtube.com/watch?v=FzmQTC_X5R4">GC</a>. So I decided to implement my
own for the <a href="https://github.com/kayceesrk/ocaml-multicore/tree/profile-alloc">multicore
compiler</a>.
Since the allocation profiler will be useful in general, I have also ported it
to <a href="https://github.com/kayceesrk/ocaml/tree/4.02-profile-alloc">OCaml 4.02</a>.
This post talks about the vanilla OCaml allocation profiler.</p>

<h1>Bytecode allocation profiler</h1>

<p>The idea of this allocation profiler is to record the allocations and associate
them with the position in the code where the corresponding block or closure was
allocated. In particular, we do not record the call stack that led to the
allocation point, which would have provided us a more accurate picture. One can
get pretty far with just the flat profile. Running the bytecode program under
the modified interpreter produces a profile, which is then analyzed offline.</p>

<p>The bytecode interpreter of OCaml is remarkably simple, as is the patch for the
allocation profiler. In this section, I will detail the implementation of the
profiler. If you are interested in just using the profiler, do skip right to
the <a href="https://kcsrk.info/atom-ocaml.xml#instructions">instructions</a>.</p>

<p>When the bytecode is loaded by the interpreter in
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/fix_code.c#L50"><code class="language-plaintext highlighter-rouge">caml_load_code</code></a>,
it allocates an array for the bytecode. <code class="language-plaintext highlighter-rouge">caml_start_code</code> points to the start
of this array. The program counter
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c#L195"><code class="language-plaintext highlighter-rouge">pc</code></a>
is a pointer into this array. We maintain a distinct code pointer
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c#L188"><code class="language-plaintext highlighter-rouge">profile_pc</code></a>
that always points to the instruction and never its operands. The offset of
<code class="language-plaintext highlighter-rouge">profile_pc</code> from <code class="language-plaintext highlighter-rouge">caml_start_code</code> uniquely identifies a instruction in the
bytecode executable. We will use this offset to record the allocation points.</p>

<p>We allocate an array
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/startup.c#L418"><code class="language-plaintext highlighter-rouge">caml_profile_counts</code></a>
of unsigned integers whose length is equal to the length of the code, into
which we will store the allocation counts. There are two main ways in which
OCaml allocates memory;
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/caml/memory.h#L71"><code class="language-plaintext highlighter-rouge">Alloc_small</code></a>
for allocating in minor heap, and
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/memory.c#L405"><code class="language-plaintext highlighter-rouge">caml_alloc_shr</code></a>
for allocating in major heap. We modify both to record the allocations at a
given instruction. We modify
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c"><code class="language-plaintext highlighter-rouge">interp.c</code></a>
to update <code class="language-plaintext highlighter-rouge">profile_pc</code> for instructions which potentially allocate. Allocations
for arrays and strings are performed in their corresponding C functions through
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/alloc.c#L30"><code class="language-plaintext highlighter-rouge">caml_alloc</code></a>.
Such allocations are covered by recording the instruction in
<a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/interp.c#L69"><code class="language-plaintext highlighter-rouge">Setup_for_c_call</code></a>.</p>

<p><code class="language-plaintext highlighter-rouge">caml_alloc_shr</code> is also used by the GC for promoting live minor heap objects
to major heap at the end of a minor GC cycle. Allocations by GC is ignored by
resetting <code class="language-plaintext highlighter-rouge">profile_pc</code> to <code class="language-plaintext highlighter-rouge">NULL</code> before minor collections. Hence, the profiler
only counts allocations by the mutator. Finally, the interpreter <a href="https://github.com/kayceesrk/ocaml/blob/ec9496b2485eee5be14e43d1d99b2b37a8d3b3da/byterun/startup.c#L450">outputs the
profile</a>
at the end of execution of the program.</p>

<div> </div>
<p>#Using the profiler</p>

<p>In order to use the profiler, compile the OCaml programs with the bytecode
compiler <code class="language-plaintext highlighter-rouge">ocamlc</code> with <code class="language-plaintext highlighter-rouge">-g</code> option to record the debugging information. This
will be used to interpret the profile. When using <code class="language-plaintext highlighter-rouge">ocamlbuild</code> it is necessary
to compile and link with <code class="language-plaintext highlighter-rouge">-g</code> (with <code class="language-plaintext highlighter-rouge">-cflag -g -lflag -g</code>).</p>

<p>First, get OCaml 4.02 with the allocation profiler, and build it using
<a href="https://github.com/gasche/opam-compiler-conf"><code class="language-plaintext highlighter-rouge">opam-compiler-conf</code></a>:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>git clone https://github.com/kayceesrk/ocaml
<span class="nv">$ </span><span class="nb">cd </span>ocaml
<span class="nv">$ </span>git checkout 4.02-profile-alloc
<span class="nv">$ </span>opam compiler-conf configure
<span class="nv">$ </span>make world.opt
<span class="nv">$ </span>opam compiler-conf <span class="nb">install</span></code></pre></figure>

<p>Let us profile the <a href="http://caml.inria.fr/pub/old_caml_site/Examples/oc/basics/queens.ml">Eight
Queens</a>
program. Profiling is enabled by setting the <code class="language-plaintext highlighter-rouge">CAML_PROFILE_ALLOC</code> to the output
filename of the profile.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>wget http://caml.inria.fr/pub/old_caml_site/Examples/oc/basics/queens.ml
<span class="nv">$ </span>ocamlc <span class="nt">-o</span> queens <span class="nt">-g</span> queens.ml
<span class="nv">$ CAML_PROFILE_ALLOC</span><span class="o">=</span>queens.preprof ./queens
Chess boards<span class="s1">'s size ? 8
The 8 queens problem has 92 solutions.

Do you want to see the solutions &lt;n/y&gt; ? n
$ ./tools/allocprof queens.preprof &gt; queens.prof
$ head -n5 queens.prof
Total: 80,433 words
Instr   Words   % of total
-----   -----   ----------
2488    31440   39.09%
27681   31440   39.09%</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">allocprof</code> is a small python script that post-processes the profile. The
post-processed profile shows the total number of words allocated, and is
followed by the instruction number, words allocated and the percentage of total
allocation that it represents. The instruction number can be linked back to the
source code by dumping the bytecode executable with <code class="language-plaintext highlighter-rouge">dumpobj</code>.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>./tools/dumpobj queens <span class="o">&gt;</span> queens.dumpobj
<span class="nv">$ </span>vim queens.prof queens.dump queens.ml</code></pre></figure>

<p><img src="https://kcsrk.info/assets/queens-profile-alloc.png" alt="Profiling 8 queens"/></p>

<p>We can see that the program spent 39.09% of allocations for appending to lists
in <code class="language-plaintext highlighter-rouge">queens.ml</code> line 61. For the curious, the other 39.09% was spent in
<code class="language-plaintext highlighter-rouge">List.map</code> function.</p>

<h1>Dealing with early termination</h1>

<div> </div>

<p>The profiler normally writes out the profile at the end of the standard program
termination, when the interpreter has run to completion. However, programs may
terminate early by explicitly invoking <code class="language-plaintext highlighter-rouge">exit</code>. In such cases, the runtime does
not get a chance to output the profile. Hence, a function <code class="language-plaintext highlighter-rouge">output_profile: unit
-&gt; unit</code> is provided to explicitly request the profile to be written out to the
filename provided in <code class="language-plaintext highlighter-rouge">CAML_PROFILE_ALLOC</code>. The following example illustrates
the use case in a program that uses the <code class="language-plaintext highlighter-rouge">Async</code> library:</p>

<figure class="highlight"><pre><code class="language-ocaml" data-lang="ocaml"><span class="c">(* foo.ml *)</span>
<span class="k">open</span> <span class="nn">Core</span><span class="p">.</span><span class="nc">Std</span>
<span class="k">open</span> <span class="nn">Async</span><span class="p">.</span><span class="nc">Std</span>

<span class="k">let</span> <span class="n">main</span> <span class="bp">()</span> <span class="o">=</span>
  <span class="n">printf</span> <span class="s2">&quot;Hello!</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">;</span>
  <span class="c">(* Without this call, profile isn't written out *)</span>
  <span class="n">output_profile</span> <span class="bp">()</span><span class="p">;</span>
  <span class="n">return</span> <span class="bp">()</span>

<span class="k">let</span> <span class="bp">()</span> <span class="o">=</span>
  <span class="nn">Command</span><span class="p">.</span><span class="n">async_basic</span>
    <span class="o">~</span><span class="n">summary</span><span class="o">:</span><span class="s2">&quot;foo&quot;</span>
    <span class="nn">Command</span><span class="p">.</span><span class="nn">Spec</span><span class="p">.(</span><span class="n">empty</span><span class="p">)</span>
    <span class="n">main</span>
  <span class="o">|&gt;</span> <span class="nn">Command</span><span class="p">.</span><span class="n">run</span></code></pre></figure>

<p>The program is compiled and run as follows:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>ocamlbuild <span class="nt">-use-ocamlfind</span> foo.byte <span class="nt">-package</span> core <span class="nt">-package</span> async <span class="nt">-tag</span> thread <span class="nt">-tag</span> debug
Finished, 3 targets <span class="o">(</span>0 cached<span class="o">)</span> <span class="k">in </span>00:00:00.
<span class="nv">$ CAML_PROFILE_ALLOC</span><span class="o">=</span>foo.preprof ./foo.byte
Hello!
<span class="nv">$ </span><span class="nb">ls </span>foo.preprof
foo.preprof</code></pre></figure>

<p>Thanks to <a href="https://github.com/trevorsummerssmith">trevorsummerssmith</a> for the
motivation and the example.</p>

<h1>Conclusion</h1>

<p>The allocation profiler has been quite useful for optimizing small programs. It
would be interesting to see whether it scales to larger ones. Also, here is my
(non-exhaustive) wish list of features:</p>

<ul>
  <li>Improve tooling. Avoid the need to manually search through text files.</li>
  <li>Record stack allocation. This is especially important in multicore OCaml
  <a href="http://kcsrk.info/#ocaml15">since stacks are heap allocated</a>.</li>
  <li>Record the call stack information for allocations to get an informative profile.</li>
  <li>Dump the profile every few milliseconds to study the allocation behavior of
  programs over time.</li>
  <li>Save the <a href="https://ocaml.org/meetings/ocaml/2013/proposals/profiling-memory.pdf">location information in the object
  header</a>
  and dump the heap at every GC to catch space leaks.</li>
</ul>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li role="doc-endnote">
      <p>Profiling for time does give you the time that the program spends in garbage collection functions such as minor GC cycles and major GC slices, but are not helpful for pinpointing allocation bottlenecks.&nbsp;<a href="https://kcsrk.info/atom-ocaml.xml#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

