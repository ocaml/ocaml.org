<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>http://www.mega-nerd.com/erikd/Blog/index.rss20</id><title type="text">mega-nerd</title><updated>2023-06-07T05:45:50-00:00</updated><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/what_do_you_mean.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
Disclaimer: I work at Ambiata (our
	&lt;a href=&quot;https://github.com/ambiata/&quot;&gt;Github&lt;/a&gt;
presence) probably the biggest Haskell shop in the southern hemisphere.
Although I mention some of Ambiata's coding practices, in this blog post I am
speaking for myself and not for Ambiata.
However, the way I'm using &lt;b&gt;&lt;tt&gt;ExceptT&lt;/tt&gt;&lt;/b&gt; and handling exceptions in
this post is something I learned from my colleagues at Ambiata.
&lt;/p&gt;

&lt;p&gt;
At work, I've been spending some time tracking down exceptions in some of our
Haskell code that have been bubbling up to the top level an killing a complex
multi-threaded program.
On Friday I posted a somewhat flippant comment to
	&lt;a href=&quot;https://plus.google.com/+ErikdeCastroLopo/posts/TbRiXuNucED&quot;&gt;Google Plus&lt;/a&gt;:
&lt;/p&gt;

&lt;blockquote&gt;
Using exceptions for control flow is the root of many evils in software.&amp;iuml;&amp;raquo;&amp;iquest;
&lt;/blockquote&gt;

&lt;p&gt;
Lennart Kolmodin who I remember from my very earliest days of using Haskell in
2008 and who I met for the first time at ICFP in Copenhagen in 2011 responded:
&lt;/p&gt;

&lt;blockquote&gt;
Yet what to do if you want composable code? Currently I have&lt;br/&gt;
type Rpc a = ExceptT RpcError IO a&lt;br/&gt;
which is terrible
&lt;/blockquote&gt;

&lt;p&gt;
But what do we mean by &amp;quot;composable&amp;quot;?
I like the
	&lt;a href=&quot;https://en.wikipedia.org/wiki/Composability&quot;&gt;wikipedia&lt;/a&gt;
definition:
&lt;/p&gt;

&lt;blockquote&gt;
&amp;iuml;&amp;raquo;&amp;iquest;Composability is a system design principle that deals with the inter-relationships
of components. A highly composable system provides recombinant components that
can be selected and assembled in various combinations to satisfy specific user
requirements.
&lt;/blockquote&gt;

&lt;p&gt;
The ensuing discussion, which also included Sean Leather, suggested that these
two experienced Haskellers were not aware that with the help of some combinator
functions, &lt;b&gt;&lt;tt&gt;ExceptT&lt;/tt&gt;&lt;/b&gt; composes very nicely and results in more
readable and more reliable code.
&lt;/p&gt;

&lt;p&gt;
At Ambiata, our coding guidelines strongly discourage the use of partial
functions.
Since the type signature of a function doesn't include information about the
exceptions it might throw, the use of exceptions is strongly discouraged.
When using library functions that may throw exceptions, we try to catch those
exceptions as close as possible to their source and turn them into
errors that are explicit in the type signatures of the code we write.
Finally, we avoid using &lt;b&gt;&lt;tt&gt;String&lt;/tt&gt;&lt;/b&gt; to hold errors.
Instead we construct data types to carry error messages and render functions
to convert them to &lt;b&gt;&lt;tt&gt;Text&lt;/tt&gt;&lt;/b&gt;.
&lt;/p&gt;

&lt;p&gt;
In order to properly demonstrate the ideas, I've written some demo code and
made it available in
	&lt;a href=&quot;https://github.com/erikd/exceptT-demo&quot;&gt;this GitHub repo&lt;/a&gt;.
It compiles and even runs (providing you give it the required number of command
line arguments) and hopefully does a good job demonstrating how the bits fit
together.
&lt;/p&gt;

&lt;p&gt;
So lets look at the naive version of a program that doesn't do any exception
handling at all.
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  import Data.ByteString.Char8 (readFile, writeFile)

  import Naive.Cat (Cat, parseCat)
  import Naive.Db (Result, processWithDb, renderResult, withDatabaseConnection)
  import Naive.Dog (Dog, parseDog)

  import Prelude hiding (readFile, writeFile)

  import System.Environment (getArgs)
  import System.Exit (exitFailure)

  main :: IO ()
  main = do
    args &amp;lt;- getArgs
    case args of
      [inFile1, infile2, outFile] -&amp;gt; processFiles inFile1 infile2 outFile
      _ -&amp;gt; putStrLn &amp;quot;Expected three file names.&amp;quot; &amp;gt;&amp;gt; exitFailure

  readCatFile :: FilePath -&amp;gt; IO Cat
  readCatFile fpath = do
    putStrLn &amp;quot;Reading Cat file.&amp;quot;
    parseCat &amp;lt;$&amp;gt; readFile fpath

  readDogFile :: FilePath -&amp;gt; IO Dog
  readDogFile fpath = do
    putStrLn &amp;quot;Reading Dog file.&amp;quot;
    parseDog &amp;lt;$&amp;gt; readFile fpath

  writeResultFile :: FilePath -&amp;gt; Result -&amp;gt; IO ()
  writeResultFile fpath result = do
    putStrLn &amp;quot;Writing Result file.&amp;quot;
    writeFile fpath $ renderResult result

  processFiles :: FilePath -&amp;gt; FilePath -&amp;gt; FilePath -&amp;gt; IO ()
  processFiles infile1 infile2 outfile = do
    cat &amp;lt;- readCatFile infile1
    dog &amp;lt;- readDogFile infile2
    result &amp;lt;- withDatabaseConnection $ \ db -&amp;gt;
                 processWithDb db cat dog
    writeResultFile outfile result

&lt;/pre&gt;

&lt;p&gt;
Once built as per the instructions in the repo, it can be run with:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  dist/build/improved/improved Naive/Cat.hs Naive/Dog.hs /dev/null
  Reading Cat file 'Naive/Cat.hs'
  Reading Dog file 'Naive/Dog.hs'.
  Writing Result file '/dev/null'.

&lt;/pre&gt;


&lt;p&gt;
The above code is pretty naive and there is zero indication of what can and
cannot fail or how it can fail.
Here's a list of some of the obvious failures that may result in an exception
being thrown:
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Either of the two &lt;b&gt;&lt;tt&gt;readFile&lt;/tt&gt;&lt;/b&gt; calls.&lt;/li&gt;
&lt;li&gt;The &lt;b&gt;&lt;tt&gt;writeFile&lt;/tt&gt;&lt;/b&gt; call.&lt;/li&gt;
&lt;li&gt;The parsing functions &lt;b&gt;&lt;tt&gt;parseCat&lt;/tt&gt;&lt;/b&gt; and
	&lt;b&gt;&lt;tt&gt;parseDog&lt;/tt&gt;&lt;/b&gt;.&lt;/li&gt;
&lt;li&gt;Opening the database connection.&lt;/li&gt;
&lt;li&gt;The database connection could terminate during the processing stage.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
So lets see how the use of the standard &lt;b&gt;&lt;tt&gt;Either&lt;/tt&gt;&lt;/b&gt; type,
&lt;b&gt;&lt;tt&gt;ExceptT&lt;/tt&gt;&lt;/b&gt; from the &lt;b&gt;&lt;tt&gt;transformers&lt;/tt&gt;&lt;/b&gt; package and
combinators from Gabriel Gonzales' &lt;b&gt;&lt;tt&gt;errors&lt;/tt&gt;&lt;/b&gt; package can improve
things.
&lt;/p&gt;

&lt;p&gt;
Firstly the types of &lt;b&gt;&lt;tt&gt;parseCat&lt;/tt&gt;&lt;/b&gt; and &lt;b&gt;&lt;tt&gt;parseDog&lt;/tt&gt;&lt;/b&gt; were
ridiculous.
Parsers can fail with parse errors, so these should both return an
&lt;b&gt;&lt;tt&gt;Either&lt;/tt&gt;&lt;/b&gt; type.
Just about everything else should be in the &lt;b&gt;&lt;tt&gt;ExceptT e IO&lt;/tt&gt;&lt;/b&gt;
monad.
Lets see what that looks like:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  {-# LANGUAGE OverloadedStrings #-}
  import           Control.Exception (SomeException)
  import           Control.Monad.IO.Class (liftIO)
  import           Control.Error (ExceptT, fmapL, fmapLT, handleExceptT
                                 , hoistEither, runExceptT)

  import           Data.ByteString.Char8 (readFile, writeFile)
  import           Data.Monoid ((&amp;lt;&amp;gt;))
  import           Data.Text (Text)
  import qualified Data.Text as T
  import qualified Data.Text.IO as T

  import           Improved.Cat (Cat, CatParseError, parseCat, renderCatParseError)
  import           Improved.Db (DbError, Result, processWithDb, renderDbError
                               , renderResult, withDatabaseConnection)
  import           Improved.Dog (Dog, DogParseError, parseDog, renderDogParseError)

  import           Prelude hiding (readFile, writeFile)

  import           System.Environment (getArgs)
  import           System.Exit (exitFailure)

  data ProcessError
    = ECat CatParseError
    | EDog DogParseError
    | EReadFile FilePath Text
    | EWriteFile FilePath Text
    | EDb DbError

  main :: IO ()
  main = do
    args &amp;lt;- getArgs
    case args of
      [inFile1, infile2, outFile] -&amp;gt;
              report =&amp;lt;&amp;lt; runExceptT (processFiles inFile1 infile2 outFile)
      _ -&amp;gt; do
          putStrLn &amp;quot;Expected three file names, the first two are input, the last output.&amp;quot;
          exitFailure

  report :: Either ProcessError () -&amp;gt; IO ()
  report (Right _) = pure ()
  report (Left e) = T.putStrLn $ renderProcessError e


  renderProcessError :: ProcessError -&amp;gt; Text
  renderProcessError pe =
    case pe of
      ECat ec -&amp;gt; renderCatParseError ec
      EDog ed -&amp;gt; renderDogParseError ed
      EReadFile fpath msg -&amp;gt; &amp;quot;Error reading '&amp;quot; &amp;lt;&amp;gt; T.pack fpath &amp;lt;&amp;gt; &amp;quot;' : &amp;quot; &amp;lt;&amp;gt; msg
      EWriteFile fpath msg -&amp;gt; &amp;quot;Error writing '&amp;quot; &amp;lt;&amp;gt; T.pack fpath &amp;lt;&amp;gt; &amp;quot;' : &amp;quot; &amp;lt;&amp;gt; msg
      EDb dbe -&amp;gt; renderDbError dbe


  readCatFile :: FilePath -&amp;gt; ExceptT ProcessError IO Cat
  readCatFile fpath = do
    liftIO $ putStrLn &amp;quot;Reading Cat file.&amp;quot;
    bs &amp;lt;- handleExceptT handler $ readFile fpath
    hoistEither . fmapL ECat $ parseCat bs
    where
      handler :: SomeException -&amp;gt; ProcessError
      handler e = EReadFile fpath (T.pack $ show e)

  readDogFile :: FilePath -&amp;gt; ExceptT ProcessError IO Dog
  readDogFile fpath = do
    liftIO $ putStrLn &amp;quot;Reading Dog file.&amp;quot;
    bs &amp;lt;- handleExceptT handler $ readFile fpath
    hoistEither . fmapL EDog $ parseDog bs
    where
      handler :: SomeException -&amp;gt; ProcessError
      handler e = EReadFile fpath (T.pack $ show e)

  writeResultFile :: FilePath -&amp;gt; Result -&amp;gt; ExceptT ProcessError IO ()
  writeResultFile fpath result = do
    liftIO $ putStrLn &amp;quot;Writing Result file.&amp;quot;
    handleExceptT handler . writeFile fpath $ renderResult result
    where
      handler :: SomeException -&amp;gt; ProcessError
      handler e = EWriteFile fpath (T.pack $ show e)

  processFiles :: FilePath -&amp;gt; FilePath -&amp;gt; FilePath -&amp;gt; ExceptT ProcessError IO ()
  processFiles infile1 infile2 outfile = do
    cat &amp;lt;- readCatFile infile1
    dog &amp;lt;- readDogFile infile2
    result &amp;lt;- fmapLT EDb . withDatabaseConnection $ \ db -&amp;gt;
                 processWithDb db cat dog
    writeResultFile outfile result

&lt;/pre&gt;

&lt;p&gt;
The first thing to notice is that changes to the structure of the main
processing function &lt;b&gt;&lt;tt&gt;processFiles&lt;/tt&gt;&lt;/b&gt; are minor but &lt;i&gt;all&lt;/i&gt; errors
are now handled explicitly.
In addition, all possible exceptions are caught as close as possible to the
source and turned into errors that are explicit in the function return types.
Sceptical?
Try replacing one of the  &lt;b&gt;&lt;tt&gt;readFile&lt;/tt&gt;&lt;/b&gt; calls with an
&lt;b&gt;&lt;tt&gt;error&lt;/tt&gt;&lt;/b&gt; call or a &lt;b&gt;&lt;tt&gt;throw&lt;/tt&gt;&lt;/b&gt; and see it get caught
and turned into an error as specified by the type of the function.
&lt;/p&gt;

&lt;p&gt;
We also see that despite having many different error types (which happens when
code is split up into many packages and modules), a constructor for an error
type higher in the stack can encapsulate error types lower in the stack.
For example, this value of type &lt;b&gt;&lt;tt&gt;ProcessError&lt;/tt&gt;&lt;/b&gt;:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  EDb (DbError3 ResultError1)

&lt;/pre&gt;

&lt;p&gt;
contains a &lt;b&gt;&lt;tt&gt;DbError&lt;/tt&gt;&lt;/b&gt; which in turn contains a
&lt;b&gt;&lt;tt&gt;ResultError&lt;/tt&gt;&lt;/b&gt;.
Nesting error types like this aids composition, as does the separation of error
rendering (turning an error data type into text to be printed) from printing.
&lt;/p&gt;

&lt;p&gt;
We also see that with the use of combinators like
	&lt;a href=&quot;https://hackage.haskell.org/package/errors-2.2.0/docs/Data-EitherR.html#v:fmapLT&quot;&gt;&lt;b&gt;&lt;tt&gt;fmapLT&lt;/tt&gt;&lt;/b&gt;&lt;/a&gt;,
and the nested error types of the previous paragraph, means that
&lt;b&gt;&lt;tt&gt;ExceptT&lt;/tt&gt;&lt;/b&gt; monad transformers do compose.
&lt;/p&gt;

&lt;p&gt;
Using &lt;b&gt;&lt;tt&gt;ExceptT&lt;/tt&gt;&lt;/b&gt; with the combinators from the
&lt;b&gt;&lt;tt&gt;errors&lt;/tt&gt;&lt;/b&gt; package to catch exceptions as close as possible to their
source and converting them to errors has numerous benefits including:
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; Errors are explicit in the types of the functions, making the code easier
	to reason about.&lt;/li&gt;
&lt;li&gt; Its easier to provide better error messages and more context than what
	is normally provided by the &lt;b&gt;&lt;tt&gt;Show&lt;/tt&gt;&lt;/b&gt; instance of most
	exceptions.&lt;/li&gt;
&lt;li&gt; The programmer spends less time chasing the source of exceptions in large
	complex code bases.&lt;/li&gt;
&lt;li&gt; More robust code, because the programmer is forced to think about and
	write code to handle errors instead of error handling being and optional
	afterthought.
	&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
Want to discuss this?
Try &lt;a href=&quot;https://www.reddit.com/r/haskell/comments/68kyfx/what_do_you_mean_exceptt_doesnt_compose/&quot;&gt;reddit&lt;/a&gt;.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/what_do_you_mean.html</id><title type="text">What do you mean ExceptT doesn't Compose?</title><updated>2017-04-30T02:22:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/forgive_me.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
Forgive me Curry and Howard for I have sinned.
&lt;/p&gt;

&lt;p&gt;
For the last several weeks, I have been writing C++ code.
I've been doing some experimentation in the area of real-time audio Digital
Signal Processing experiments, C++ actually is better than Haskell.
&lt;/p&gt;

&lt;p&gt;
Haskell is simply not a good fit here because I need:
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt; To be able to guarantee (by inspection) that there is zero memory
	allocation/de-allocation in the real-time inner processing loop. &lt;/li&gt;
&lt;li&gt; Things like IIR filters are inherently stateful, with their internal state
	being updated on every input sample.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
There is however one good thing about coding C++; I am constantly reminded of
all the sage advice about C++ I got from my friend Peter Miller who passed
away a bit over a year ago.
&lt;/p&gt;

&lt;p&gt;
Here is an example of the code I'm writing:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  class iir2_base
  {
      public :
          // An abstract base class for 2nd order IIR filters.
          iir2_base () ;

          // Virtual destructor does nothing.
          virtual ~iir2_base () { }

          inline double process (double in)
          {
              unsigned minus2 = (minus1 + 1) &amp;amp; 1 ;
              double out = b0 * in + b1 * x [minus1] + b2 * x [minus2]
                              - a1 * y [minus1] - a2 * y [minus2] ;
              minus1 = minus2 ;
              x [minus1] = in ;
              y [minus1] = out ;
              return out ;
          }

      protected :
          // iir2_base internal state (all statically allocated).
          double b0, b1, b2 ;
          double a1, a2 ;
          double x [2], y [2] ;
          unsigned minus1 ;

      private :
          // Disable copy constructor etc.
          iir2_base (const iir2_base &amp;amp;) ;
          iir2_base &amp;amp; operator = (const iir2_base &amp;amp;) ;
  } ;

&lt;/pre&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/forgive_me.html</id><title type="text">Forgive me Curry and Howard for I have Sinned.</title><updated>2015-11-16T11:22:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/building-llvm-fuzzer.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
I've been using the awesome
	&lt;a href=&quot;http://lcamtuf.coredump.cx/afl/&quot;&gt;American Fuzzy Lop&lt;/a&gt;
fuzzer since late last year but had also heard good things about the
	&lt;a href=&quot;http://llvm.org/docs/LibFuzzer.html&quot;&gt;LLVM Fuzzer&lt;/a&gt;.
Getting the code for the LLVM Fuzzer is trivial, but when I tried to use it, I
ran into all sorts of road blocks.
&lt;/p&gt;

&lt;p&gt;
Firstly, the LLVM Fuzzer needs to be compiled with and used with Clang (GNU GCC
won't work) and it needs to be Clang &amp;gt;= 3.7.
Now Debian does ship a clang-3.7 in the Testing and Unstable releases, but that
package has a bug
	&lt;a href=&quot;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=779785&quot;&gt;(#779785)&lt;/a&gt;
which means the Debian package is missing the static libraries required by the
	&lt;a href=&quot;http://clang.llvm.org/docs/AddressSanitizer.html&quot;&gt;Address Sanitizer&lt;/a&gt;
options.
Use of the Address Sanitizers (and other sanitizers) increases the effectiveness
of fuzzing tremendously.
&lt;/p&gt;

&lt;p&gt;
This bug meant I had to build Clang from source, which nnfortunately, is rather
poorly documented (I intend to submit a patch to improve this) and I only
managed it with help from the #llvm IRC channel.
&lt;/p&gt;

&lt;p&gt;
Building Clang from the git mirror can be done as follows:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  mkdir LLVM
  cd LLVM/
  git clone http://llvm.org/git/llvm.git
  (cd llvm/tools/ &amp;amp;&amp;amp; git clone http://llvm.org/git/clang.git)
  (cd llvm/projects/ &amp;amp;&amp;amp; git clone http://llvm.org/git/compiler-rt.git)
  (cd llvm/projects/ &amp;amp;&amp;amp; git clone http://llvm.org/git/libcxx.git)
  (cd llvm/projects/ &amp;amp;&amp;amp; git clone http://llvm.org/git/libcxxabi)

  mkdir -p llvm-build
  (cd llvm-build/ &amp;amp;&amp;amp; cmake -G &amp;quot;Unix Makefiles&amp;quot; -DCMAKE_INSTALL_PREFIX=$(HOME)/Clang/3.8 ../llvm)
  (cd llvm-build/ &amp;amp;&amp;amp; make install)

&lt;/pre&gt;

&lt;p&gt;
If all the above works, you will now have working &lt;b&gt;&lt;tt&gt;clang&lt;/tt&gt;&lt;/b&gt; and
&lt;b&gt;&lt;tt&gt;clang++&lt;/tt&gt;&lt;/b&gt; compilers installed in &lt;b&gt;&lt;tt&gt;$HOME/Clang/3.8/bin&lt;/tt&gt;&lt;/b&gt;
and you can then follow the examples in the
	&lt;a href=&quot;http://llvm.org/docs/LibFuzzer.html&quot;&gt;LLVM Fuzzer documentation&lt;/a&gt;.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/building-llvm-fuzzer.html</id><title type="text">Building the LLVM Fuzzer on Debian.</title><updated>2015-07-21T10:08:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/ghci-trick.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
Just found a really nice little hack that makes working in the GHC interactive
	&lt;a href=&quot;https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop&quot;&gt;REPL&lt;/a&gt;
a little easier and more convenient.
First of all, I added the following line to my &lt;b&gt;&lt;tt&gt;~/.ghci&lt;/tt&gt;&lt;/b&gt; file.
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  :set -DGHC_INTERACTIVE

&lt;/pre&gt;

&lt;p&gt;
All that line does is define a &lt;b&gt;&lt;tt&gt;GHC_INTERACTIVE&lt;/tt&gt;&lt;/b&gt; pre-processor
symbol.
&lt;/p&gt;

&lt;p&gt;
Then in a file that I want to load into the REPL, I need to add this to the top
of the file:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  {-# LANGUAGE CPP #-}

&lt;/pre&gt;

&lt;p&gt;
and then in the file I can do things like:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  #ifdef GHC_INTERACTIVE
  import Data.Aeson.Encode.Pretty

  prettyPrint :: Value -&amp;gt; IO ()
  prettyPrint = LBS.putStrLn . encodePretty
  #endif

&lt;/pre&gt;

&lt;p&gt;
In this particular case, I'm working with some relatively large chunks of JSON
and its useful to be able to pretty print them when I'm the REPL, but I have
no need for that function when I compile that module into my project.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/ghci-trick.html</id><title type="text">Haskell : A neat trick for GHCi</title><updated>2014-10-17T22:16:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/wai_3.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
Michael Snoyman has just released version 3.0 of
	&lt;a href=&quot;http://hackage.haskell.org/package/wai/&quot;&gt;
	Wai&lt;/a&gt;,
the Haskell Web Application Interface library which is used with the
	&lt;a href=&quot;http://www.yesodweb.com/&quot;&gt;
	Yesod Web Framework&lt;/a&gt;
and anything that uses the
	&lt;a href=&quot;http://hackage.haskell.org/package/warp&quot;&gt;
	Warp&lt;/a&gt;
web server.
The important changes for Wai are listed this
	&lt;a href=&quot;http://www.yesodweb.com/blog/2014/05/wai-3-0-alpha&quot;&gt;
	blog post&lt;/a&gt;.
The tl;dr is that removing the Conduit library dependency makes the Wai
interface more easily usable with one of the alternative Haskell streaming
libraries, like Pipes, Stream-IO, Iterator etc.
&lt;/p&gt;

&lt;p&gt;
As a result of the above changes, the type of a web application changes as
follows:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  -- Wai &amp;gt; 2.0 &amp;amp;&amp;amp; Wai &amp;lt; 3.0
  type Application = Request -&amp;gt; IO Response

  -- Wai == 3.0
  type Application = Request -&amp;gt; (Response -&amp;gt; IO ResponseReceived) -&amp;gt; IO ResponseReceived

&lt;/pre&gt;

&lt;p&gt;
Typically a function of type &lt;b&gt;&lt;tt&gt;Application&lt;/tt&gt;&lt;/b&gt; will be run by the Warp
web server using one of &lt;b&gt;&lt;tt&gt;Warp.run&lt;/tt&gt;&lt;/b&gt; or associated functions which
have type signatures of:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  run :: Port -&amp;gt; Application -&amp;gt; IO ()

  runSettings :: Settings -&amp;gt; Application -&amp;gt; IO ()

  runSettingsSocket :: Settings -&amp;gt; Socket -&amp;gt; Application -&amp;gt; IO ()Source

  runSettingsConnection :: Settings -&amp;gt; IO (Connection, SockAddr) -&amp;gt; Application -&amp;gt; IO ()

&lt;/pre&gt;

&lt;p&gt;
Its important to note that the only thing that has changed about these Warp
functions is the &lt;b&gt;&lt;tt&gt;Application&lt;/tt&gt;&lt;/b&gt; type.
That means that if we have a function &lt;b&gt;&lt;tt&gt;oldWaiApplication&lt;/tt&gt;&lt;/b&gt; that we
want to interface to the new version of Wai, we can just wrap it with the
following function:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  newWaiApplication :: Manager -&amp;gt; Request -&amp;gt; (Response -&amp;gt; IO ResponseReceived) -&amp;gt; IO ResponseReceived
  newWaiApplication mgr wreq receiver = oldWaiApplication mgr wreq &amp;gt;&amp;gt;= receiver

&lt;/pre&gt;

&lt;p&gt;
and use &lt;b&gt;&lt;tt&gt;newWaiApplication&lt;/tt&gt;&lt;/b&gt; in place of &lt;b&gt;&lt;tt&gt;oldWaiApplication&lt;/tt&gt;&lt;/b&gt;
in the call to whichever of the Warp &lt;b&gt;&lt;tt&gt;run&lt;/tt&gt;&lt;/b&gt; functions you are using.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/wai_3.html</id><title type="text">Moving from Wai 2.X to 3.0.</title><updated>2014-06-11T10:16:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/quickcheck_fail.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
This is an old trick I picked up from a colleague over a decade ago and have
re-invented or re-remembered a number of times since.
&lt;/p&gt;

&lt;p&gt;
When implementing complicated performance critical algorithms and things
don't work immediately, the best idea is to drop back to the old formula of:
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Make it compile.&lt;/li&gt;
&lt;li&gt;Make it correct.&lt;/li&gt;
&lt;li&gt;Make it fast.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
Often than means implementing slow naive versions of parts of the algorithm
first and then one-by-one replacing the slow versions with fast versions.
For a given function of two inputs, this might give me two functions with the
identical type signatures:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

   functionSlow :: A -&amp;gt; B -&amp;gt; C
   functionFast :: A -&amp;gt; B -&amp;gt; C

&lt;/pre&gt;

&lt;p&gt;
that can be used interchangeably.
&lt;/p&gt;

&lt;p&gt;
When it comes to implementing the fast versions, the slow versions can be used
to check the correct-ness of the fast version using a simple QuickCheck property
like:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

   \ a b -&amp;gt; functionFast a b == functionSlow a b

&lt;/pre&gt;

&lt;p&gt;
This property basically just asks QuickCheck to generate a, b pairs, pass these
to both functions and compare their outputs.
&lt;/p&gt;

&lt;p&gt;
With something like this, QuickCheck usually all finds the corner cases really
quickly.
Except for when it doesn't.
QuickCheck uses a random number generator to generate inputs to the function
under test.
If for instance you have a function that takes a floating point number and only
behaves incorrectly when that input is say exactly 10.3, the chances of QuickCheck
generating exactly 10.3 and hitting the bug are very small.
&lt;/p&gt;

&lt;p&gt;
For exactly this reason, using the technique above sometimes doesn't work.
Sometimes the fast version has a bug that Quickcheck wasn't able to find.
&lt;/p&gt;

&lt;p&gt;
When this happens the trick is to write a third function:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  functionChecked :: A -&amp;gt; B -&amp;gt; C
  functionChecked a b =
      let fast = functionFast a b
          slow = functionSlow a b
      in if fast == slow
           then fast
           else error $ &amp;quot;functionFast &amp;quot; ++ show a ++ &amp;quot; &amp;quot; ++ show b
                ++ &amp;quot;\nreturns    &amp;quot; ++ show fast
                ++ &amp;quot;\n should be &amp;quot; ++ show slow

&lt;/pre&gt;

&lt;p&gt;
which calculates the function output using both the slow and the fast versions,
compares the outputs and fails with an error if the two function outputs are not
identical.
&lt;/p&gt;


&lt;p&gt;
Using this in my algorithm I can then collect failing test cases that QuickCheck
couldn't find.
With a failing test case, its usually pretty easy to fix the broken fast
version of the function.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/quickcheck_fail.html</id><title type="text">When QuickCheck Fails Me</title><updated>2014-01-08T10:03:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/integer_pt1.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
Haskellers may or not be aware that there are two libraries in the GHC sources
for implementing the &lt;tt&gt;Integer&lt;/tt&gt; data type.
&lt;/p&gt;

&lt;p&gt;
The first,
	&lt;a href=&quot;http://git.haskell.org/packages/integer-gmp.git&quot;&gt;&lt;tt&gt;integer-gmp&lt;/tt&gt;&lt;/a&gt;
links to the
	&lt;a href=&quot;https://gmplib.org/&quot;&gt;GNU Multiple Precision Arithmetic Library&lt;/a&gt;
which is licensed under the GNU LGPL.
On most systems, libgmp is dynamically linked and all is fine.
However, if you want to create statically linked binaries from Haskell source code
you end up with your executable statically linking libgmp which means your binary
needs to be under an LGPL compatible license if you want to release it.
This is especially a problem on iOS which doesn't allow dynamic linking anyway.
&lt;/p&gt;

&lt;p&gt;
The second &lt;tt&gt;Integer&lt;/tt&gt; implementation is
	&lt;a href=&quot;http://git.haskell.org/packages/integer-simple.git&quot;&gt;&lt;tt&gt;integer-simple&lt;/tt&gt;&lt;/a&gt;
which is implemented purely in Haskell (using a number of GHC extension) and is
BSD licensed.
&lt;/p&gt;

&lt;p&gt;
So why doesn't everyone just the the BSD licensed one?
Well, &lt;tt&gt;integer-simple&lt;/tt&gt; has a reputation for being slow.
Even more intriguingly, I seem to remember Duncan Coutts telling me a couple of
years ago that &lt;tt&gt;integer-simple&lt;/tt&gt; was a little faster than &lt;tt&gt;integer-gmp&lt;/tt&gt;
when the &lt;tt&gt;Integer&lt;/tt&gt; was small enough to fit in a single machine &lt;tt&gt;Word&lt;/tt&gt;,
but much slower when that was not the case.
At the time I heard this, I decided to look into it at some time.
That time has come.
&lt;/p&gt;

&lt;p&gt;
A couple of weeks ago I put together some scripts and code to allow me to compile
the two &lt;tt&gt;Integer&lt;/tt&gt; implementations into a single program and benchmark them
against each other.
My initial results looked like this:
&lt;/p&gt;

&lt;img src=&quot;http://www.mega-nerd.com/erikd/Img/integer-gmp-simple.png&quot; border=&quot;0&quot; alt=&quot;Integer performance (GMP vs Simple)&quot;/&gt;

&lt;p&gt;
That confirmed the slowness for multiplication and division if nothing else.
&lt;/p&gt;

&lt;p&gt;
Taking a look at the code to &lt;tt&gt;integer-simple&lt;/tt&gt; I found that it was storing
&lt;tt&gt;Word#&lt;/tt&gt;s (unboxed machine sized words) in a Haskell list.
As convenient as lists are they are not an optimal data structure for a something
like the &lt;tt&gt;Integer&lt;/tt&gt; library.
&lt;/p&gt;

&lt;p&gt;
I have already started work on replacement for both versions of the current
&lt;tt&gt;Integer&lt;/tt&gt; library with the following properties:
&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt; BSD licensed.&lt;/li&gt;
	&lt;li&gt; Implemented in Haskell (with GHC extensions) so there are no issues
			with linking to external C libraries.&lt;/li&gt;
	&lt;li&gt; Fast. I'm aiming to outperform both &lt;tt&gt;integer-simple&lt;/tt&gt; and
			&lt;tt&gt;integer-gmp&lt;/tt&gt; on as many benchmarks as possible.&lt;/li&gt;
	&lt;li&gt; Few dependencies so it can easily replace the existing versions.
			Currently my code only depends on &lt;tt&gt;ghc-prim&lt;/tt&gt; and
			&lt;tt&gt;primitive&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
So far the results are looking encouraging.
For &lt;tt&gt;Integer&lt;/tt&gt; values smaller than a machine word, addition with my prototype
code is faster than both existing libraries and for adding large integers its
currently half the speed of &lt;tt&gt;integer-gmp&lt;/tt&gt;, but I have an idea which will
likely make the new library match the speed of &lt;tt&gt;integer-gmp&lt;/tt&gt;.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/integer_pt1.html</id><title type="text">Haskell : The Problem with Integer.</title><updated>2013-12-28T23:08:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/parMap.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
I had a long running, CPU intensive Haskell program that I wanted to speed up.
The program was basically a loop consisting of a a small sequential part
followed by a &lt;tt&gt;map&lt;/tt&gt; of a CPU intensive pure function over a list of 1500
elements.
&lt;/p&gt;

&lt;p&gt;
Obviously I needed some sort of parallel map function and I had a faint
recollection of a function called &lt;tt&gt;parMap&lt;/tt&gt;.
The wonderful
	&lt;a href=&quot;http://www.haskell.org/hoogle/&quot;&gt;
	Hoogle search engine&lt;/a&gt;
pointed me to the
	&lt;a href=&quot;http://hackage.haskell.org/packages/archive/parallel/latest/doc/html/Control-Parallel-Strategies.html#v:parMap&quot;&gt;
	&lt;tt&gt;parMap&lt;/tt&gt; documentation&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
Changing the existing sequential &lt;tt&gt;map&lt;/tt&gt; operation into a parallel map
required a 3 line change (one of them to import the required module).
I then added &amp;quot;&lt;tt&gt;-threaded&lt;/tt&gt;&amp;quot; to the compile command line to enable the
threaded runtime system in the generated executable and &amp;quot;&lt;tt&gt;+RTS -N6&lt;/tt&gt;&amp;quot; to
the executable's command line.
The resulting program went from using 100% of 1 CPU to using 560% of 1 CPU on an
8 CPU box.
Win!
&lt;/p&gt;

&lt;p&gt;
I wish all code was this easy to parallelize.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/parMap.html</id><title type="text">parMap to the Rescue.</title><updated>2013-01-22T11:08:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/my_space_is_leaking.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
Over the last couple of days I wrote a small Haskell program to read a large CSV
file (75Meg, approx. 1000 columns and 50000 rows) and calculate some statistics.
Since I would have to do this for much larger files as well, I decided to use
the
	&lt;a href=&quot;http://hackage.haskell.org/package/csv-conduit/&quot;&gt;
	csv-conduit&lt;/a&gt;
library to read the data and use a function passed to &lt;tt&gt;Data.Conduit&lt;/tt&gt;'s
	&lt;a href=&quot;http://hackage.haskell.org/packages/archive/conduit/latest/doc/html/Data-Conduit-Util.html#v:sinkState&quot;&gt;
	sinkState&lt;/a&gt;
to calculate the statistics.
&lt;/p&gt;

&lt;p&gt;
The code was pretty easy to put together, and only came to about 100 lines of
code.
Unfortunately, when I ran the program, it tried to consume all 8Gig of memory
on my laptop and when I actually let it run to completion, it took over an hour
to produce useful output.
&lt;/p&gt;

&lt;p&gt;
A bit of quick profiling showed that the problem was with the state used to hold
the statistics.
The state itself wasn't huge, but Haskell's lazy evaluation meant there were a
huge number of thunks (pending calculations) piling up.
&lt;/p&gt;

	&lt;blockquote&gt;
	Aside : Haskell does lazy (more correctly called non-strict) evaluation by
	default.
	This means that values are calculated when they are needed rather than when
	the program hits that point in the code.
	For instance if a value is generated by calling a pure function, the GHC runtime
	will forgo actually calling the function and replace the value with a thunk
	containing the function and it's input parameters.
	Later, when the value is actually needed, the runtime will call the function
	stored in the thunk.
	&lt;/blockquote&gt;

&lt;p&gt;
My first attempt to fix this problem was to add some strictness annotations to
my data types, but that didn't seem to help.
I then looked at the
	&lt;a href=&quot;http://hackage.haskell.org/package/deepseq/&quot;&gt;
	deepseq&lt;/a&gt;
package and tried adding the
	&lt;a href=&quot;http://hackage.haskell.org/packages/archive/deepseq/1.3.0.1/doc/html/Control-DeepSeq.html#v:-36--33--33-&quot;&gt;
	&lt;tt&gt;$!!&lt;/tt&gt;&lt;/a&gt;
operator in a few places.
This resulted in a compile error complaining about my data structures not having
an
	&lt;a href=&quot;http://hackage.haskell.org/packages/archive/deepseq/1.3.0.1/doc/html/Control-DeepSeq.html#t:NFData&quot;&gt;
	NFData&lt;/a&gt;
instance.
A bit of googling for &amp;quot;custom NFData instance&amp;quot; showed up the
	&lt;a href=&quot;http://hackage.haskell.org/package/deepseq-th/&quot;&gt;
	deepseq-th&lt;/a&gt;
package which uses Template Haskell to generate NFData instances.
&lt;/p&gt;

	&lt;blockquote&gt;
	Aside : For a value to be an instance of the NFData typeclass means that
	it can be fully evaluated, ie a thunk to calculate a value of this type can
	be forced by deepseq to replace the thunk with the value.
	&lt;/blockquote&gt;

&lt;p&gt;
About 10 minutes later I had my code working again, but now it processed the same
file in a little over 2 minutes and used less than 0.1% of the 8Gig it was using
previously.
&lt;/p&gt;

&lt;p&gt;
I was happy with this.
So happy that I decided to thank the author of deepseq-th, Herbert Valerio Riedel
(hvr) on the #haskell IRC channel.
Herbert was pleased to hear of my success, but suggested that instead of
deepseq-th I try using
	&lt;a href=&quot;http://hackage.haskell.org/package/deepseq-generics/&quot;&gt;
	deepseq-generics&lt;/a&gt;.
Someone else on the channel suggested that this might be slower, but Herbert
said that he had not found that to be the case.
Switching from one to the other was trivially easy and pleasingly enough the
generics version ran just as fast.
&lt;/p&gt;

&lt;p&gt;
That's when Jos&amp;Atilde;&amp;copy; Pedro Magalh&amp;Atilde;&amp;pound;es (dreixel in #haskell) said that he had a draft
paper
	&lt;a href=&quot;http://dreixel.net/research/pdf/ogpi_draft.pdf&quot;&gt;
	&amp;quot;Optimisation of Generic Programs through Inlining&amp;quot;&lt;/a&gt;
explaining how and why this generic implementation is just as fast as the
Template Haskell version.
Basically it boils down to the compiler having all the information it needs at
compile time to inline and specialize the code to be just as fast as hand written
code.
&lt;/p&gt;

&lt;p&gt;
Reflections:
&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Streaming I/O libraries like Data.Conduit (there's more than one) do
		give guarantees about space usage so that when you get a space leak the
		I/O is probably not the first place to look.
		&lt;/li&gt;
	&lt;li&gt;For small programs its relatively easy to reason about where the space
		leak is happening.
		&lt;/li&gt;
	&lt;li&gt;For a relatively experienced Haskeller, following the bread crumbs to
		a working solution is relatively easy.
		&lt;/li&gt;
	&lt;li&gt;Code that uses a struct to accumulate state is a common contributor to
		space leaks.
		&lt;/li&gt;
	&lt;li&gt;Interacting with the Haskell community can often get a better result
		than the first thing you find (eg deepseq-generics instead of deepseq-th).
		&lt;/li&gt;
	&lt;li&gt;Generics can be just as fast as Template Haskell generated code.
		&lt;/li&gt;
&lt;/ol&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/my_space_is_leaking.html</id><title type="text">My Space is Leaking.</title><updated>2012-12-22T05:42:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/read_int.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
I'm currently working on converting my
	&lt;a href=&quot;http://hackage.haskell.org/package/http-proxy/&quot;&gt;
	http-proxy&lt;/a&gt;
library from using the
	&lt;a href=&quot;http://hackage.haskell.org/package/enumerator&quot;&gt;
	Data.Enumerator&lt;/a&gt;
package to
	&lt;a href=&quot;http://hackage.haskell.org/package/conduit/&quot;&gt;
	Data.Conduit&lt;/a&gt;
(explanation of why in my
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/telnet-conduit.html&quot;&gt;
	last blog post&lt;/a&gt;).
&lt;/p&gt;

&lt;p&gt;
During this conversion, I have been studying the sources of the
	&lt;a href=&quot;http://hackage.haskell.org/package/warp/&quot;&gt;
	Warp&lt;/a&gt;
web server because my http-proxy was originally derived from the Enumerator
version of Warp.
While digging through the Warp code I found the following code (and comment)
which is used to parse the number provided in the &lt;tt&gt;Content-Length&lt;/tt&gt; field
of a HTTP header:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  -- Note: This function produces garbage on invalid input. But serving an
  -- invalid content-length is a bad idea, mkay?
  readInt :: S.ByteString -&amp;gt; Integer
  readInt = S.foldl' (\x w -&amp;gt; x * 10 + fromIntegral w - 48) 0

&lt;/pre&gt;

&lt;p&gt;
The comment clearly states that that this function can produce garbage,
specifically if the string contains anything other than ASCII digits.
The comment is also correct that an invalid &lt;tt&gt;Content-Length&lt;/tt&gt; is a bad
idea.
However, on seeing the above code, and remembering something I had seen recently
in the standard library, I naively sent the
	&lt;a href=&quot;https://github.com/yesodweb/wai/&quot;&gt;
	Yesod project&lt;/a&gt;
a patch replacing the above code with a version that uses the &lt;tt&gt;readDec&lt;/tt&gt;
function from the &lt;tt&gt;Numeric&lt;/tt&gt; module:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  import Data.ByteString (ByteString)
  import qualified Data.ByteString.Char8 as B
  import qualified Numeric as N

  readInt :: ByteString -&amp;gt; Integer
  readInt s =
      case N.readDec (B.unpack s) of
          [] -&amp;gt; 0
          (x, _):_ -&amp;gt; x

&lt;/pre&gt;

&lt;p&gt;
About 3-4 hours after I submitted the patch I got an email from
	&lt;a href=&quot;http://www.snoyman.com/&quot;&gt;
	Michael Snoyman&lt;/a&gt;
saying that parsing the &lt;tt&gt;Content-Length&lt;/tt&gt; field is a hot spot for the
performance of Warp and that I should benchmark it against the code I'm
replacing to make sure there is no unacceptable performance penalty.
&lt;/p&gt;

&lt;p&gt;
That's when I decided it was time to check out Bryan O'Sullivan's
	&lt;a href=&quot;http://hackage.haskell.org/package/criterion/&quot;&gt;
	Criterion&lt;/a&gt;
bench-marking library.
A quick read of the docs and bit of messing around and I was able to prove to
myself that using &lt;tt&gt;readDec&lt;/tt&gt; was indeed much slower than the code I wanted
to replace.
&lt;/p&gt;

&lt;p&gt;
The initial disappointment of finding that a more correct implementation was
significantly slower than the less correct version quickly turned to joy as I
experimented with a couple of other implementations and eventually settled on
this:
&lt;/p&gt;


&lt;pre class=&quot;code&quot;&gt;

  import Data.ByteString (ByteString)
  import qualified Data.ByteString.Char8 as B
  import qualified Data.Char as C

  readIntTC :: Integral a =&amp;gt; ByteString -&amp;gt; a
  readIntTC bs = fromIntegral
          $ B.foldl' (\i c -&amp;gt; i * 10 + C.digitToInt c) 0
          $ B.takeWhile C.isDigit bs

&lt;/pre&gt;

&lt;p&gt;
By using the &lt;tt&gt;Integral&lt;/tt&gt; type class, this function converts the given
&lt;tt&gt;ByteString&lt;/tt&gt; to any integer type (ie any type belonging to the
&lt;tt&gt;Integral&lt;/tt&gt; type class).
When used, this function will be specialized by the Haskell compiler at the
call site to to produce code to read string values into &lt;tt&gt;Int&lt;/tt&gt;s,
&lt;tt&gt;Int64&lt;/tt&gt;s or anything else that is a member of the &lt;tt&gt;Integral&lt;/tt&gt;
type class.
&lt;/p&gt;

&lt;p&gt;
For a final sanity check I decided to use
	&lt;a href=&quot;http://hackage.haskell.org/package/QuickCheck&quot;&gt;
	QuickCheck&lt;/a&gt;
to make sure that the various versions of the generic function were correct for
values of the type they returned.
To do that I wrote a very simple QuickCheck property as follows:
&lt;/p&gt;


&lt;pre class=&quot;code&quot;&gt;

  prop_read_show_idempotent :: Integral a =&amp;gt; (ByteString -&amp;gt; a) -&amp;gt; a -&amp;gt; Bool
  prop_read_show_idempotent freader x =
      let posx = abs x
      in posx == freader (B.pack $ show posx)

&lt;/pre&gt;

&lt;p&gt;
This QuickCheck property takes the function under test &lt;tt&gt;freader&lt;/tt&gt; and
QuickCheck will then provide it values of the correct type.
Since the function under test is designed to read &lt;tt&gt;Content-Length&lt;/tt&gt; values
which are always positive, we only test using the absolute value of the value
randomly generated by QuickCheck.
&lt;/p&gt;


&lt;p&gt;
The complete test program can be found on Github
	&lt;a href=&quot;https://gist.github.com/1662654&quot;&gt;
	in this Gist&lt;/a&gt;
and can be compiled and run as:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  ghc -Wall -O3 --make readInt.hs -o readInt &amp;amp;&amp;amp; ./readInt

&lt;/pre&gt;

&lt;p&gt;
When run, the output of the program looks like this:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  Quickcheck tests.
  +++ OK, passed 100 tests.
  +++ OK, passed 100 tests.
  +++ OK, passed 100 tests.
  Criterion tests.
  warming up
  estimating clock resolution...
  mean is 3.109095 us (320001 iterations)
  found 27331 outliers among 319999 samples (8.5%)
    4477 (1.4%) low severe
    22854 (7.1%) high severe
  estimating cost of a clock call...
  mean is 719.4627 ns (22 iterations)

  benchmarking readIntOrig
  mean: 4.653041 us, lb 4.645949 us, ub 4.663823 us, ci 0.950
  std dev: 43.94805 ns, lb 31.52653 ns, ub 73.82125 ns, ci 0.950

  benchmarking readDec
  mean: 13.12692 us, lb 13.10881 us, ub 13.14411 us, ci 0.950
  std dev: 90.63362 ns, lb 77.52619 ns, ub 112.4304 ns, ci 0.950

  benchmarking readRaw
  mean: 591.8697 ns, lb 590.9466 ns, ub 594.1634 ns, ci 0.950
  std dev: 6.995869 ns, lb 3.557109 ns, ub 14.54708 ns, ci 0.950

  benchmarking readInt
  mean: 388.3835 ns, lb 387.9500 ns, ub 388.8342 ns, ci 0.950
  std dev: 2.261711 ns, lb 2.003214 ns, ub 2.585137 ns, ci 0.950

  benchmarking readInt64
  mean: 389.4380 ns, lb 388.9864 ns, ub 389.9312 ns, ci 0.950
  std dev: 2.399116 ns, lb 2.090363 ns, ub 2.865227 ns, ci 0.950

  benchmarking readInteger
  mean: 389.3450 ns, lb 388.8463 ns, ub 389.8626 ns, ci 0.950
  std dev: 2.599062 ns, lb 2.302428 ns, ub 2.963600 ns, ci 0.950

&lt;/pre&gt;

&lt;p&gt;
At the top of the output is proof that all three specializations of the generic
function &lt;tt&gt;readIntTC&lt;/tt&gt; satisfy the QuickCheck property.
From the Criterion output its pretty obvious that the &lt;tt&gt;Numeric.readDec&lt;/tt&gt;
version is about 3 times slower that the original function.
More importantly, all three version of this generic function are an order of
magnitude faster than the original.
&lt;/p&gt;

&lt;p&gt;
That's a win!
I will be submitting my new function for inclusion in Warp.
&lt;/p&gt;


&lt;p&gt;
&lt;b&gt;Update : 14:13&lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;
At around the same time I submitted my latest version for &lt;tt&gt;readInt&lt;/tt&gt;
Vincent Hanquez
	&lt;a href=&quot;https://github.com/yesodweb/wai/pull/34#issuecomment-3626110&quot;&gt;
	posted a comment on the Github issue&lt;/a&gt;
suggesting I look at the
	&lt;a href=&quot;http://www.haskell.org/ghc/docs/7.2.2/html/users_guide/syntax-extns.html#magic-hash&quot;&gt;
	GHC MagicHash extension&lt;/a&gt;
and pointed me to
	&lt;a href=&quot;http://tab.snarc.org/posts/haskell/2011-11-15-lookup-tables.html&quot;&gt;
	an example&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
Sure enough, using the MagicHash technique resulted in something significantly
faster again.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;Update #2 : 2012-01-29 19:46&lt;/b&gt;
&lt;/p&gt;

&lt;p&gt;
In version 0.3.0 and later of the
	&lt;a href=&quot;http://hackage.haskell.org/package/bytestring-lexing&quot;&gt;
	bytestring-lexing&lt;/a&gt;
package there is a function &lt;tt&gt;readDecimal&lt;/tt&gt; that is even faster than the
MagiHash version.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/read_int.html</id><title type="text">Benchmarking and QuickChecking readInt.</title><updated>2012-01-24T00:52:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/telnet-conduit.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
Below is a simple telnet client written using Haskell's new
	&lt;a href=&quot;http://hackage.haskell.org/package/conduit/&quot;&gt;
	Conduit&lt;/a&gt;
library.
This library was written by
	&lt;a href=&quot;http://www.snoyman.com/&quot;&gt;Michael Snoyman&lt;/a&gt;
the man behind the
	&lt;a href=&quot;http://www.yesodweb.com/&quot;&gt;
	Yesod&lt;/a&gt;
Web Framework for Haskell.
&lt;/p&gt;

&lt;p&gt;
The Conduit library is a second generation approach to the problem of
guaranteeing bounded memory usage in the presence of lazy evaluation.
The first generation of these ideas were libraries like
	&lt;a href=&quot;http://hackage.haskell.org/package/iteratee&quot;&gt;
	Iteratee&lt;/a&gt;,
	&lt;a href=&quot;http://hackage.haskell.org/package/enumerator&quot;&gt;
	Enumerator&lt;/a&gt;,
and
	&lt;a href=&quot;http://hackage.haskell.org/package/iterIO&quot;&gt;
	IterIO&lt;/a&gt;.
All of these first generation libraries use the the term &lt;i&gt;enumerator&lt;/i&gt;
for data producers and &lt;i&gt;iteratee&lt;/i&gt; for data consumers.
The new Conduit library calls data producers &lt;i&gt;&amp;quot;sources&amp;quot;&lt;/i&gt; and data consumers
&lt;i&gt;&amp;quot;sinks&amp;quot;&lt;/i&gt; to make them a little more approachable.
&lt;/p&gt;

&lt;p&gt;
The other big difference between Conduit and the early libraries in this space
is to do with guaranteeing early clean up of potentially scarce resources like
sockets.
Although I have not looked in any detail at the IterIO library, both Iteratee and
Enumerator simply rely on Haskell's garbage collector to clean up resources
when they are no longer required.
The Conduit library on the other hand uses
	&lt;a href=&quot;http://hackage.haskell.org/packages/archive/conduit/latest/doc/html/Control-Monad-Trans-Resource.html&quot;&gt;
	Resource transformers&lt;/a&gt;
to guarantee release of these resources as soon as possible.
&lt;/p&gt;

&lt;p&gt;
The client looks like this
(&lt;a href=&quot;https://gist.github.com/1596792&quot;&gt;latest available here&lt;/a&gt;):
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  import Control.Concurrent (forkIO, killThread)
  import Control.Monad.IO.Class (MonadIO, liftIO)
  import Control.Monad.Trans.Resource
  import Data.Conduit
  import Data.Conduit.Binary
  import Network (connectTo, PortID (..))
  import System.Environment (getArgs, getProgName)
  import System.IO


  main :: IO ()
  main = do
      args &amp;lt;- getArgs
      case args of
          [host, port] -&amp;gt; telnet host (read port :: Int)
          _ -&amp;gt; usageExit
    where
      usageExit = do
          name &amp;lt;- getProgName
          putStrLn $ &amp;quot;Usage : &amp;quot; ++ name ++ &amp;quot; host port&amp;quot;


  telnet :: String -&amp;gt; Int -&amp;gt; IO ()
  telnet host port = runResourceT $ do
      (releaseSock, hsock) &amp;lt;- with (connectTo host $ PortNumber $ fromIntegral port) hClose
      liftIO $ mapM_ (`hSetBuffering` LineBuffering) [ stdin, stdout, hsock ]
      (releaseThread, _) &amp;lt;- with (
                            forkIO $ runResourceT $ sourceHandle stdin $$ sinkHandle hsock
                            ) killThread
      sourceHandle hsock $$ sinkHandle stdout
      release releaseThread
      release releaseSock

&lt;/pre&gt;

&lt;p&gt;
There are basically three blocks, a bunch of imports at the top, the program's
entry point &lt;b&gt;&lt;tt&gt;main&lt;/tt&gt;&lt;/b&gt; and the &lt;b&gt;&lt;tt&gt;telnet&lt;/tt&gt;&lt;/b&gt; function.
&lt;/p&gt;

&lt;p&gt;
The &lt;b&gt;&lt;tt&gt;telnet&lt;/tt&gt;&lt;/b&gt; function is pretty simple.
Most of the function runs inside a &lt;b&gt;&lt;tt&gt;runResourceT&lt;/tt&gt;&lt;/b&gt; resource
transformer.
The purpose of these resources transformers is to keep track of resources such
as sockets, file handles, thread ids etc and make sure they get released in a
timely manner.
For example, in the &lt;b&gt;&lt;tt&gt;telnet&lt;/tt&gt;&lt;/b&gt; function, the &lt;b&gt;&lt;tt&gt;connectTo&lt;/tt&gt;&lt;/b&gt;
function call opens a connection to the specified host and port number and
returns a socket.
By wrapping the &lt;b&gt;&lt;tt&gt;connectTo&lt;/tt&gt;&lt;/b&gt; in the call to &lt;b&gt;&lt;tt&gt;with&lt;/tt&gt;&lt;/b&gt;
then the socket is registered with the resource transformer.
The &lt;b&gt;&lt;tt&gt;with&lt;/tt&gt;&lt;/b&gt; function has the following prototype:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  with :: Resource m
       =&amp;gt; Base m a             -- Base monad for the current monad stack
       -&amp;gt; (a -&amp;gt; Base m ())     -- Resource de-allocation function
       -&amp;gt; ResourceT m (ReleaseKey, a)

&lt;/pre&gt;

&lt;p&gt;
When the resource is registered, the user must also supply a function that will
destroy and release the resource.
The &lt;b&gt;&lt;tt&gt;with&lt;/tt&gt;&lt;/b&gt; function returns a &lt;b&gt;&lt;tt&gt;ReleaseKey&lt;/tt&gt;&lt;/b&gt; for the
resource and the resource itself.
Formulating the &lt;b&gt;&lt;tt&gt;with&lt;/tt&gt;&lt;/b&gt; function this way makes it hard to misuse.
&lt;/p&gt;

&lt;p&gt;
The other thing of interest is that because a telnet client needs to send data
in both directions, the server-to-client communication path and the
client-to-server communication run in separate GHC runtime threads.
The thread is spawned using &lt;b&gt;&lt;tt&gt;forkIO&lt;/tt&gt;&lt;/b&gt; and even though the thread
identifier is thrown away, the resource transformer still records it and will
later call &lt;b&gt;&lt;tt&gt;killThread&lt;/tt&gt;&lt;/b&gt; to clean up the thread.
&lt;/p&gt;

&lt;p&gt;
The main core of the program are the two lines containing calls to
&lt;b&gt;&lt;tt&gt;sourceHandle&lt;/tt&gt;&lt;/b&gt; and &lt;b&gt;&lt;tt&gt;sinkHandle&lt;/tt&gt;&lt;/b&gt;.
The first of these lines pulls data from &lt;b&gt;&lt;tt&gt;stdin&lt;/tt&gt;&lt;/b&gt; and pushes it to
the socket &lt;b&gt;&lt;tt&gt;hsock&lt;/tt&gt;&lt;/b&gt; while the second pulls from the socket and
pushes it to &lt;b&gt;&lt;tt&gt;stdout&lt;/tt&gt;&lt;/b&gt;.
&lt;/p&gt;

&lt;p&gt;
It should be noted that the final two calls to &lt;b&gt;&lt;tt&gt;release&lt;/tt&gt;&lt;/b&gt; are not
strictly necessary since the resource transformer will clean up these resources
automatically.
&lt;/p&gt;

&lt;p&gt;
The experience of writing this telnet client suggests that the Conduit library
is certainly easier to use than the Enumerator or Iteratee libraries.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Haskell/telnet-conduit.html</id><title type="text">A Simple Telnet Client Using Data.Conduit.</title><updated>2012-01-14T02:22:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/michael_mak.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">
&lt;center&gt;
        &lt;img src=&quot;http://www.mega-nerd.com/erikd/Img/michael_mak.jpg&quot; border=&quot;0&quot; alt=&quot;Michael Mak&quot;/&gt;
&lt;/center&gt;

&lt;br/&gt;
&lt;p&gt;
On the same day that the computing world lost Steve Jobs, the company I work
for lost its own star, founder and CEO of bCODE, Michael Mak.
&lt;/p&gt;

&lt;p&gt;
I remember meeting Michael in late 2005 when I first came to interview for a job
with bCODE.
Michael impressed me immediately with his keen intelligence and his easy going
personality.
As I worked with him over the years, my respect grew.
I came to trust him and the rest of the management team far more than I had
ever trusted any other employer.
I always felt that Michael saw the employees as an important part of the company
and he wouldn't do anything to further the company at the expense of the
employees.
This was even true when he had to retrench a third of the workforce after the
global financial crisis of 2008.
I saw first hand how much distress this caused him and our COO.
&lt;/p&gt;

&lt;p&gt;
When Michael moved the business side of the enterprise to the US, he would still
make regular trips back to visit the Sydney office.
During these visits three or four of us would go out to lunch and he would
regale us with tales of people he met and deals that he was working on.
These were exciting times and Michael was a great motivator.
&lt;/p&gt;

&lt;p&gt;
The things I will remember about Michael was his enthusiasm, his integrity, his
leadership and just being a great all round guy.
&lt;/p&gt;

&lt;p&gt;
My condolences to his family and his girlfriend Emily.
No one will miss Michael as much as them.
&lt;/p&gt;

&lt;p&gt;
Michael was 37 years old.
&lt;/p&gt;



</content><id>http://www.mega-nerd.com/erikd/Blog/michael_mak.html</id><title type="text">Michael Man Ho Mak RIP.</title><updated>2011-10-09T01:07:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_very_nearly_done.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
The LLVM backend for
	&lt;a href=&quot;http://disciple.ouroborus.net/&quot;&gt;
	DDC&lt;/a&gt;
that I've been working on sporadically
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_backend.html&quot;&gt;
	since June&lt;/a&gt;
is basically done.
When compiling via the LLVM backend, all but three of 100+ tests in the DDC
test suite pass.
The tests that pass when going via the C backend but fail via the LLVM backend
are of two kinds:
&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Use DDC's &lt;tt&gt;&lt;b&gt;foreign import&lt;/b&gt;&lt;/tt&gt; construct to name a C macro
		 to perform a type cast where the macro is defined in one of C header
		 files.
		&lt;/li&gt;
	&lt;li&gt;Use static inline functions in the C backend to do peek and poke
		operations on arrays of unboxed values.
		&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;
In both of these cases, DDC is using features of the C language to make code
generation easier.
Obviously, the LLVM backend needs to do something else to get the same effect.
&lt;/p&gt;

&lt;p&gt;
Fixing the type casting problem should be relatively simple.
&lt;a href=&quot;http://www.cse.unsw.edu.au/~benl/&quot;&gt;
	Ben&lt;/a&gt;
is currently working on making type casts a primitive of the Core language
so that both the C and LLVM backends can easily generate code for them.
&lt;/p&gt;

&lt;p&gt;
The array peek and poke problem is little more complex.
I suspect that it too will require the addition of new Core language primitive
operations.
This is a much more complex problem than the type casting one and I've only just
begun to start thinking about it.
&lt;/p&gt;

&lt;p&gt;
Now that the backend is nearly done, its not unreasonable to look at its
performance.
The following table shows the compile and run times of a couple of tests in the
DDC test suite compiling via the C and the LLVM backend.
&lt;/p&gt;

&lt;br/&gt;

&lt;center&gt;
&lt;table class=&quot;simple&quot;&gt;
	&lt;tr&gt;
		&lt;th&gt;Test name&lt;/th&gt;
			&lt;th&gt;C Build Time&lt;/th&gt;
			&lt;th&gt;LLVM Build Time&lt;/th&gt;
			&lt;th&gt;C Run Time&lt;/th&gt;
			&lt;th&gt;LLVM Run Time&lt;/th&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;th align=&quot;left&quot;&gt;93-Graphics/Circle&lt;/th&gt;
			&lt;td align=&quot;right&quot;&gt;3.124s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;3.260s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;1.701s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;1.536s&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;th align=&quot;left&quot;&gt;93-Graphics/N-Body/Boxed&lt;/th&gt;
			&lt;td align=&quot;right&quot;&gt;6.126s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;6.526s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;7.649s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;4.899s&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;th align=&quot;left&quot;&gt;93-Graphics/N-Body/UnBoxed&lt;/th&gt;
			&lt;td align=&quot;right&quot;&gt;3.559s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;4.017s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;9.843s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;6.162s&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;th align=&quot;left&quot;&gt;93-Graphics/RayTracer&lt;/th&gt;
			&lt;td align=&quot;right&quot;&gt;12.890s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;13.102s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;13.465s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;8.973s&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
 		&lt;th align=&quot;left&quot;&gt;93-Graphics/SquareSpin&lt;/th&gt;
			&lt;td align=&quot;right&quot;&gt;2.699s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;2.889s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;1.609s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;1.604s&lt;/td&gt;
	&lt;/tr&gt;
	&lt;tr&gt;
		&lt;th align=&quot;left&quot;&gt;93-Graphics/Styrene&lt;/th&gt;
			&lt;td align=&quot;right&quot;&gt;13.685s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;14.349s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;11.312s&lt;/td&gt;
			&lt;td align=&quot;right&quot;&gt;8.527s&lt;/td&gt;
	&lt;/tr&gt;

&lt;/table&gt;
&lt;/center&gt;

&lt;br/&gt;

&lt;p&gt;
Although there is a small increase in compile times when compiling via LLVM, the
LLVM run times are significantly reduced.
The conceptual complexity of the LLVM backend is also low (the line count is
about 4500 lines, which will probably fall with re-factoring) and thanks to
LLVM's type checking being significantly better than C's, I think its reasonable
to be more confident in the quality of the LLVM backend than the existing C
backend.
Finally, implementing things like proper tail call optimisation will be far
easier in LLVM backend than in C.
&lt;/p&gt;

&lt;p&gt;
All in all, I think doing this LLVM backend has been an interesting challenge
and will definitely pay off in the long run.
&lt;/p&gt;

</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_very_nearly_done.html</id><title type="text">LLVM Backend for DDC : Very Nearly Done.</title><updated>2011-01-01T02:54:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_milestone3.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
After my
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_backend2.html&quot;&gt;
	last post&lt;/a&gt;
on this topic, I ran into some problems with the AST (abstract syntax tree) that
was being passed to my code for LLVM code generation.
After discussing the problem with Ben, he spent some time cleaning up the AST
definition, the result of which was that nearly all the stuff I already had,
stopped working.
This was a little disheartening.
That and the fact that I was really busy, meant that I didn't touch the LLVM
backend for a number of weeks.
&lt;/p&gt;

&lt;p&gt;
When I finally did get back to it, I found that it wasn't as broken as I had
initially thought.
Although the immediate interface between Ben's code and mine had changed
significantly, all the helper functions I had written were still usable.
Over a week and a bit, I managed to patch everything up again and get back to
where I was.
I also did a lot of cleaning up and came up with a neat solution to a problem
which was bugging me during my previous efforts.
&lt;/p&gt;

&lt;p&gt;
The problem was that structs defined via the LLVM backend needed to have exactly
the same memory layout as the structs defined via the C backend.
This is a strict requirement for proper interaction between code generated via
C and LLVM.
This was made a little difficult by David Terei's haskell LLVM wrapper code
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_backend.html&quot;&gt;
	(see previous post)&lt;/a&gt;
which makes all structs packed by default, while structs on the C side were
not packed.
Another dimension of this problem was finding an easy way to generate LLVM code
to access structs in a way that was easy to read and debug in the code generator
and also not require different code paths for generating 32 and 64 bit code.
&lt;/p&gt;

&lt;p&gt;
Struct layout is tricky.
Consider a really simple struct like this:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  struct whatever
  {   int32_t tag ;
      char * pointer ;
  } ;

&lt;/pre&gt;

&lt;p&gt;
On a 32 bit system, that struct will take up 8 bytes; 4 bytes for the
&lt;tt&gt;&lt;b&gt;int32_t&lt;/b&gt;&lt;/tt&gt; and 4 for the pointer.
However, on a 64 bit system, where pointers are 8 bytes in size, the struct
will take up 16 bytes.
Why not 12 bytes?
Well, some 64 bit CPUs (Alpha and Sparc64 are two I can think of) are not
capable of unaligned memory accesses; a read from memory into a CPU register
where the memory address (in bytes) is not an integer multiple of the size of
the register.
Other CPUs like x86_64 can read unaligned data, but reading unaligned data is
usually slower than reading correctly aligned data.
&lt;/p&gt;

&lt;p&gt;
In order to avoid unaligned, the compiler assumes that the start address of the
struct will be aligned to the correct alignment for the biggest CPU register
element in the struct, in this case the pointer.
It then adds 4 bytes of padding between the &lt;tt&gt;&lt;b&gt;int32_t&lt;/b&gt;&lt;/tt&gt; and the
pointer to ensure that if the struct is correctly aligned then the pointer will
also be correctly aligned.
&lt;/p&gt;

&lt;p&gt;
Because structs are packed in the David Terei's code, the above struct would
require a different definition on 32 and 64 bit systems, ie
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  ; 32 bit version of the struct
  %struct.whatever.32 = type &amp;lt;{ i32, i8 * }&amp;gt;

  ; 64 bit version of the struct
  %struct.whatever.64 = type &amp;lt;{ i32, [4 * i8], i8 * }&amp;gt;

&lt;/pre&gt;

&lt;p&gt;
where the 64 bit version contains 4 padding bytes.
However, the difference between these two definitions causes another problem.
To access fields within a struct, LLVM code uses the
	&lt;a href=&quot;http://llvm.org/docs/LangRef.html#i_getelementptr&quot;&gt;
	&lt;tt&gt;&lt;b&gt;getelementptr&lt;/b&gt;&lt;/tt&gt;&lt;/a&gt;
operator which addresses fields by index.
Unfortunately, the index (zero based) of the pointer is 1 for the 32 bit version
and 2 for the 64 bit version.
That would make code generation a bit of a pain in the neck.
&lt;/p&gt;

&lt;p&gt;
The solution is allow the specification of LLVM structs in Haskell as a list of
&lt;tt&gt;&lt;b&gt;LlvmStructField&lt;/b&gt;&lt;/tt&gt; elements, using
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  data LlvmStructField
        = AField String LlvmType    -- Field name and type.
        | APadTo2                   -- Pad next field to a 2 byte offset.
        | APadTo4                   -- Pad next field to a 4 byte offset.
        | APadTo8                   -- Pad next field to a 8 byte offset.

        | APadTo8If64               -- Pad next field to a 8 byte offset only
                                    -- for 64 bit.

&lt;/pre&gt;

&lt;p&gt;
Note that the &lt;tt&gt;&lt;b&gt;AField&lt;/b&gt;&lt;/tt&gt; constructor requires both a name and the
&lt;tt&gt;&lt;b&gt;LlvmType&lt;/b&gt;&lt;/tt&gt;.
I then provide functions to convert the &lt;tt&gt;&lt;b&gt;LlvmStructField&lt;/b&gt;&lt;/tt&gt; list
into an opaque &lt;tt&gt;&lt;b&gt;LlvmStructDesc&lt;/b&gt;&lt;/tt&gt; type and provide the following
functions:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  -- | Turn an struct specified as an LlvmStructField list into an
  -- LlvmStructDesc and give it a name. The LlvmStructDesc may
  -- contain padding to make it conform to the definition.
  mkLlvmStructDesc :: String -&amp;gt; [LlvmStructField] -&amp;gt; LlvmStructDesc

  -- | Retrieve the struct's LlvmType from the LlvmStructDesc.
  llvmTypeOfStruct :: LlvmStructDesc -&amp;gt; LlvmType

  -- | Given and LlvmStructDesc and the name of a field within the
  -- LlvmStructDesc, retrieve a field's index with the struct and its
  -- LlvmType.
  structFieldLookup :: LlvmStructDesc -&amp;gt; String -&amp;gt; (Int, LlvmType)

&lt;/pre&gt;

&lt;p&gt;
Once the &lt;tt&gt;&lt;b&gt;LlvmStructDesc&lt;/b&gt;&lt;/tt&gt; is built for a given struct, fields
within the struct can be addressed in the LLVM code generator by name, making
the Haskell code generator code far easier to read.
&lt;/p&gt;

&lt;p&gt;
Pretty soon after I got the above working I also managed to get enough LLVM
code generation working to compile a complete small program which then runs
correctly.
I consider that to be milestone 3.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_milestone3.html</id><title type="text">LLVM Backend for DDC : Milestone #3.</title><updated>2010-12-01T09:41:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/fp-tail-js.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
About 6 weeks ago, I got an email from
	&lt;a href=&quot;http://blogs.atlassian.com/developer/csharkie/&quot;&gt;
	Craig Sharkie&lt;/a&gt;,
who runs the Sydney Javascript group,
	&lt;a href=&quot;http://sydjs.com/&quot;&gt;
	SydJS&lt;/a&gt;.
He was contacting me because I run the
	&lt;a href=&quot;http://groups.google.com/group/fp-syd&quot;&gt;
	Sydney functional programing group&lt;/a&gt;
and he was asking if I knew anyone who might be able to give a presentation
about tail call recursion at SydJS.
In the spirit of FP-Syd outreach I volunteered to do it, even though I haven't
really done all that much Javascript.
&lt;/p&gt;

&lt;p&gt;
On the night, I showed up, had a beer and then presented
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/files/js-tail-call.pdf&quot;&gt;
	my slides&lt;/a&gt;.
I started off explaining what functional programming is and why its is
interesting (hint; common language features like garbage collection, dynamic
typing, lambda expression and type inference all started in functional
languages).
&lt;/p&gt;

&lt;p&gt;
I used the factorial function as an example of function that can be implemented
recursively and I demoed the
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/files/js-demo/&quot;&gt;
	Javascript versions&lt;/a&gt;
in a web browser.
I gave the standard recursive form whose stack usage grows linearly with
&lt;tt&gt;&lt;b&gt;n&lt;/b&gt;&lt;/tt&gt;:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  function factorial (n)
  {
      /* Termination condition. */
      if (n &amp;lt;= 1)
          return 1 ;

    /* Recursion. */
      return n * factorial (n - 1) ;
  }

&lt;/pre&gt;

&lt;p&gt;
followed by the tail recursive form:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  function factorial (n)
  {
      function fac_helper (n, fac)
      {
          if (n &amp;lt;= 1)
              return fac ;
          return fac_helper (n - 1, n * fac) ;
      }

      return fac_helper (n, 1) ;
  }

&lt;/pre&gt;

&lt;p&gt;
Unfortunately even though this is written in tail recursive form, it still doesn't
run in constant stack space.
That's because neither the ECMAScript 3 and 5 standards mandate tail call
optimisation and few of the Javascript engines implement it.
&lt;/p&gt;

&lt;p&gt;
For languages whose compilers do implement the TCO, the above function will
run in constant stack space and I demonstrated this using the same function
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/files/mlfactorial.ml&quot;&gt;
	written in Ocaml&lt;/a&gt;:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  (* Compile using: ocamlopt nums.cmxa mlfactorial.ml -o mlfactorial *)

  open Big_int

  (*
      val mult_int_big_int : int -&amp;gt; big_int -&amp;gt; big_int
          Multiplication of a big integer by a small integer
  *)
  let ($*) = mult_int_big_int

  let factorial n =
      let rec fac_helper x fac =
          if x &amp;lt;= 1 then
              fac
          else
              fac_helper (x - 1) (x $* fac)
      in
      fac_helper n unit_big_int

  let () =
      let n = int_of_string Sys.argv.(1) in
      let facn = factorial n in
      Printf.printf &amp;quot;factorial %d = %s\n&amp;quot; n (string_of_big_int facn)

&lt;/pre&gt;

&lt;p&gt;
When this program is run through the Ocaml compiler, the compiler detects that
the factorial function is written in tail recursive form and that it can
therefore use the Tail Call Optimisation and create a executable that runs in
constant stack space.
I demostrated the constant stack space usage by running it under valgrind using
valgrind's DRD tool:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  &lt;b&gt;&amp;gt;&lt;/b&gt; valgrind --quiet --tool=drd --show-stack-usage=yes ./factorial 5
  factorial 5 = 120
  ==3320== thread 1 finished and used 11728 bytes out of 8388608 on its stack. Margin: 8376880 bytes.
  &lt;b&gt;&amp;gt;&lt;/b&gt; valgrind --quiet --tool=drd --show-stack-usage=yes ./factorial 10
  factorial 10 = 3628800
  ==3323== thread 1 finished and used 11728 bytes out of 8388608 on its stack. Margin: 8376880 bytes.
  &lt;b&gt;&amp;gt;&lt;/b&gt; valgrind --quiet --tool=drd --show-stack-usage=yes ./factorial 20
  factorial 20 = 2432902008176640000
  ==3326== thread 1 finished and used 11728 bytes out of 8388608 on its stack. Margin: 8376880 bytes.

&lt;/pre&gt;

&lt;p&gt;
Regardless of the value of &lt;tt&gt;&lt;b&gt;n&lt;/b&gt;&lt;/tt&gt; the stack space used is constant
(although, for much larger values of &lt;tt&gt;&lt;b&gt;n&lt;/b&gt;&lt;/tt&gt;, the
&lt;tt&gt;&lt;b&gt;Big_int&lt;/b&gt;&lt;/tt&gt; calculations start easting a little more stack, but
thats much less of a problem).
&lt;/p&gt;

&lt;p&gt;
Finally, I showed a way of doing TCO by hand using a technique I found in
Spencer Tipping's
	&lt;a href=&quot;https://github.com/spencertipping/js-in-ten-minutes/&quot;&gt;
	&lt;i&gt;&amp;quot;Javascipt in Ten Minutes&amp;quot;&lt;/i&gt;&lt;/a&gt;.
The solution adds a couple of new properties to the prototype of the
&lt;tt&gt;&lt;b&gt;Function&lt;/b&gt;&lt;/tt&gt; object to provide delimited continuations (another
idea from functional programming).
See the
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/files/js-demo/demo5-factorial.js&quot;&gt;
	the code&lt;/a&gt;
for the details.
Suffice to say that this solution is really elegant and should be safe to run
in just about any browser whose Javascript implementation is not completely
broken.
&lt;/p&gt;

&lt;p&gt;
As far as I am concerned, my presentation was received very well and the Twitter
responses (all two of them) ranged from
	&lt;a href=&quot;https://twitter.com/sydjs/status/4821816115728384&quot;&gt;
	&lt;i&gt;&amp;quot;brain melting&amp;quot;&lt;/i&gt;&lt;/a&gt;
to
	&lt;a href=&quot;https://twitter.com/pamelafox/status/4884534680092672&quot;&gt;
	&lt;i&gt;&amp;quot;awesome&amp;quot;&lt;/i&gt;&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
I then hung around for the rest of the meeting, had another beer and chatted to
people.
One interesting part of the meeting was called &amp;quot;Di-&lt;i&gt;script&lt;/i&gt;-ions&amp;quot;, where a
member of the audience would put up small 4-10 line snippets of Javascript code
and asked the audience what they did and why.
What was surprising to me that for some cases the semantics of a small piece of
Javascript code is completely non-obvious.
Javascript seems to have some very weird interactions between scoping rules,
whether functions are defined directly or as a variable and the sequence of
initialisation.
Strange indeed.
&lt;/p&gt;

&lt;p&gt;
Anyway, thanks to Craig Sharkie for inviting me.
I had a great time.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/fp-tail-js.html</id><title type="text">Functional Programing, Tail Call Recursion and Javascript.</title><updated>2010-11-30T10:47:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-29.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
On Thursday October 21st, we held the 29th meeting of the Sydney Functional
Programming group.
The meeting was held at Google's Sydney offices and we had about 22 people show
up to hear our two presenters.
&lt;/p&gt;

&lt;p&gt;
First up we had
	&lt;a href=&quot;http://benjaminjohnston.com.au/&quot;&gt;
	Benjamin Johnston&lt;/a&gt;
with a presentation titled &lt;i&gt;&amp;quot;How to Dance the Robot&amp;quot;&lt;/i&gt;.
As part of his work an University of Technology here in Sydney, Ben gets to
program robots.
One of the results, is robots that dance (thanks to Mark Wotton for capturing
this video on his iPhone):
&lt;/p&gt;

&lt;br/&gt;&lt;br/&gt;

&lt;center&gt;
&lt;object type=&quot;application/x-shockwave-flash&quot; width=&quot;480&quot; height=&quot;385&quot; data=&quot;http://www.youtube.com/v/PhlN_o2CrA0?fs=1&amp;amp;hl=en_US&quot;&gt;
	&lt;param name=&quot;movie&quot; value=&quot;http://www.youtube.com/v/PhlN_o2CrA0?fs=1&amp;amp;hl=en_US&quot;/&gt;
	&lt;param name=&quot;wmode&quot; value=&quot;transparent&quot;/&gt;
&lt;/object&gt;
&lt;/center&gt;

&lt;br/&gt;&lt;br/&gt;

&lt;p&gt;
Ben's language of choice is Prolog (not functional but definitely
	&lt;a href=&quot;http://c2.com/cgi/wiki?DeclarativeProgramming&quot;&gt;
	declarative&lt;/a&gt;)
and he used Prolog to tackle the problem of making the programming of a
robot dance easier.
A complete dance might last 3 minutes or more, the music is likely to have a
tempo of around 100 beats per minute and the dance moves are usually timed down
to the half beat.
That means some 600 odd half beat events for a 3 minute dance.
Entering 600 odd events manually would be somewhat tedious.
&lt;/p&gt;

&lt;p&gt;
Ben's solution to this problem was a compiler for a domain specific language
(DSL) which allowed easier specification of the dance in terms of musical
sections, repeated moves etc.
Writing the compiler was made easier by making good use of Prolog's search and
backtracking capabilities and the compiler generated Python output code that
was uploaded to the robot.
&lt;/p&gt;

&lt;p&gt;
Our second presenter for the evening was
	&lt;a href=&quot;http://seanseefried.com/&quot;&gt;
	Sean Seefried&lt;/a&gt;
on the subject of the &lt;i&gt;&amp;quot;The Expression Problem&amp;quot;&lt;/i&gt;, in Haskell.
In Sean's paper (with Manuel M. T. Chakravarty),
	&lt;a href=&quot;http://www.cse.unsw.edu.au/~chak/papers/exp-problem.pdf&quot;&gt;
	&lt;i&gt;&amp;quot;Solving the expression problem with true separate compilation&amp;quot;&lt;/i&gt;&lt;/a&gt;
he describes the expression problem as:
&lt;/p&gt;

&lt;blockquote&gt;&lt;i&gt;
&amp;quot;the difficulty of extending the variants and methods on a data type without
modifying existing code and while respecting separate compilation&amp;quot;
&lt;/i&gt;&lt;/blockquote&gt;

&lt;p&gt;
There are a number of other languages which have solutions to the expression
problem, but Sean's work was the first real Haskell solution.
With the use of multi-parameter type classes, scoped type variables, kind
annotations, zero constructor data types and recursive dictionaries, Sean was
able to make it work with GHC 6.4 and later.
At the end, Sean also presented some ideas to make the solution of this problem
easier and more practical.
&lt;/p&gt;

&lt;p&gt;
A big thanks to Ben and Sean for presenting and Google for providing the
meeting venue and refreshments.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-29.html</id><title type="text">FP-Syd #29.</title><updated>2010-11-16T11:12:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/libsndfile/malware.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
I just found a very suspicious bit torrent download available here:
&lt;/p&gt;

&lt;center&gt;
&lt;p&gt;
&lt;a href=&quot;http://www.torrentzap.com/torrent/1581031/Libsndfile+(64-Bit)+1.0.23&quot;&gt;
    http://www.torrentzap.com/torrent/1581031/Libsndfile+%2864-Bit%29+1.0.23&lt;/a&gt;
&lt;/p&gt;
&lt;/center&gt;

&lt;p&gt;
The file being shared is intended to look like the Windows 64 bit installer for
libsndfile-1.0.23 and seems to be widely available on this and a number of other
torrent sites.
&lt;/p&gt;

&lt;p&gt;
However, the file on the torrent sites is called
&lt;b&gt;&lt;tt&gt;libsndfile-64-bit-1.0.23.exe&lt;/tt&gt;&lt;/b&gt; while the one I distribute is
called
	&lt;a href=&quot;http://www.mega-nerd.com/libsndfile/files/libsndfile-1.0.23-w64-setup.exe&quot;&gt;
	&lt;b&gt;&lt;tt&gt;libsndfile-1.0.23-w64-setup.exe&lt;/tt&gt;&lt;/b&gt;&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
I haven't analyzed the torrent version of the file; I simply don't have the
tools or the knowledge to investigate it.
I don't even have access to a machine that runs 64 bit Windows.
The setup file on my website was cross compiled from Linux to 64 bit Windows
using the very wonderful
	&lt;a href=&quot;http://mingw-w64.org/&quot;&gt;
	MinGW w64&lt;/a&gt;
tools and the setup installer created using
	&lt;a href=&quot;http://www.jrsoftware.org/isinfo.php&quot;&gt;
	INNO Setup&lt;/a&gt;
running under
	&lt;a href=&quot;http://www.winehq.org/&quot;&gt;
	Wine&lt;/a&gt;.
However, the file is named differently and has a different md5sum.
That in itself is more than enough reason to be suspicious.
&lt;/p&gt;

&lt;p&gt;
The valid file that I distribute has the following md5 and sha256 sums:
&lt;/p&gt;
&lt;pre class=&quot;code&quot;&gt;

    md5sum    : efe73b7cb52724e7db7bb7d6ce145929
    sha256sum : 30896dac1002a7b509b6f4620317dad730d8ad761e4ff0402db5a94b0d4c09a2

&lt;/pre&gt;

&lt;p&gt;
I'm not really aware of how problems like this are addressed on Windows.
Is there a safe, secure, verifiable way of distributing Windows software
packages?
If so, I'd appreciate it if someone could let me know how its done.
&lt;/p&gt;

&lt;p&gt;
For Linux this is much easier.
Firstly, the vast majority of people on Linux install libsndfile via their Linux
distribution.
The person who packages libsndfile for any given distribution grabs the source
code tarball from my
	&lt;a href=&quot;http://www.mega-nerd.com/libsndfile/#Download&quot;&gt;
	web site&lt;/a&gt;.
At the same time they should also grab the GPG signature file and verify that
the source code tarball is correct and valid.
&lt;/p&gt;

&lt;p&gt;
I don't know what happens in all distributions, but in Debian, the person doing
the packaging GPG signs the package before uploading to the Debian servers.
Once the GPG signed package is uploaded, the packager's GPG signature is checked
before it goes into the unstable distribution.
From there the validity of the package is tracked all the way to where an end
user installs it on a machine via the
	&lt;a href=&quot;http://www.debian.org/doc/manuals/securing-debian-howto/ch7#s7.4.1&quot;&gt;
	process documented here&lt;/a&gt;.
This process means that its very difficult to get malware onto a Linux machine
via the distribution's package manager.
&lt;/p&gt;

&lt;p&gt;
I suppose this in one more reason why people should be running Linux rather than
Windows.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/libsndfile/malware.html</id><title type="text">libsndfile Malware on Windows.</title><updated>2010-10-16T01:11:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/libsndfile/rf64_specs.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
One of the very common sound file formats that
	&lt;a href=&quot;http://www.mega-nerd.com/libsndfile/&quot;&gt;
	libsndfile&lt;/a&gt;
reads and writes is the
	&lt;a href=&quot;http://en.wikipedia.org/wiki/WAV&quot;&gt;
	WAV&lt;/a&gt;
format.
This format uses unsigned 32 bit integers internally to specify chunk lengths
which limits the total size of well formed file to be about 4 gigabytes in size.
On modern systems with high bit widths, multiple channels and high sample rates,
this 4Gig limit can be run into very easily.
For instance at a sample rate of 96kHz, with 24 bit samples, a 5.1 surround
sound recording will run into the 4Gig limit after about 41 minutes.
&lt;/p&gt;

&lt;p&gt;
In order to overcome the limitations of WAV, the
	&lt;a href=&quot;http://www.ebu.ch/&quot;&gt;
	European Broadcasting Union&lt;/a&gt;
decided in 2006 to start the specification of an extended WAV file format
capable of handling 64 bit file offsets.
The document that resulted from this specification process was first released in
2006 and the latest update was made in 2009 and is
	&lt;a href=&quot;http://tech.ebu.ch/docs/tech/tech3306-2009.pdf&quot;&gt;
	available here&lt;/a&gt;.
I have a number of problems with this specification document.
&lt;/p&gt;

&lt;p&gt;
First and foremost, in section 3.5, the document states:
&lt;/p&gt;

&lt;blockquote&gt;&lt;i&gt;
In spite of higher sampling frequencies and multi-channel audio, some production
audio files will inevitably be smaller than 4 Gbyte and they should therefore
stay in Broadcast Wave Format.
&lt;br/&gt;&lt;br/&gt;
The problem arises that a recording application cannot know in advance whether
the recorded audio it is compiling will exceed 4 Gbyte or not at end of
recording (i.e. whether it needs to use RF64 or not).
&lt;br/&gt;&lt;br/&gt;
The solution is to enable the recording application to switch from BWF to RF64
on the fly at the 4 Gbyte size-limit, while the recording is still going on.
&lt;br/&gt;&lt;br/&gt;
This is achieved by reserving additional space in the BWF by inserting a 'JUNK'
chunk 3 that is of the same size as a 'ds64' chunk. This reserved space has no
meaning for Broadcast Wave, but will become the 'ds64' chunk, if a transition
to RF64 is necessary.
&lt;/i&gt;&lt;/blockquote&gt;

&lt;p&gt;
In short, the suggestion above for writing a file boils down to:
&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open the file and write a RIFF/WAV file header with a JUNK section big
	enough to allow the header to be replaced with an RF64 header if needed.
	&lt;/li&gt;
&lt;li&gt;If the file ends up bigger than 4 gigabytes, go back and replace the
	existing header with an RF64 header.
	&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;
There are two problems with this suggestion; it makes testing difficult and it
makes the software more complex which means its more likely to contain bugs.
The testing problem arises because testing that the RF64 header is written
correctly can only be done by writing a 4 gigabyte file.
Programmers can then either choose not to test this (which means the software is
is highly unlikely to work as specified) or test write a full 4 Gig file.
However, programmers also want their tests to run quickly (so that they can be
run often) and writing 4 gigabytes of data to disk is definitely not going to
be quick.
Of course, a smaller unit test might be able to bypass the requirement of
writing 4 gigabytes, but it would still be prudent to do a real test at the
WAV to RF64 switch over point.
The complexity problem is simply that writing a WAV file header first and then
overwriting it with an RF64 header later is far more complicated than just
writing an RF64 header to begin with.
Complexity breeds bugs.
&lt;/p&gt;

&lt;p&gt;
The libsndfile project has had, from the very beginning, a pretty comprehensive
test suite and the running of that test suite takes about 30 seconds on current
hardware.
In order to comprehensively test the reading and writing of RF64 files,
libsndfile disregards the rather silly suggestion of the EBU to convert on the
fly between WAV and RF64 files.
If the software calling libsndfile specifies that an RF64 file be generated,
libsndfile will write an RF64 file, even if that file only contains 100 bytes.
&lt;/p&gt;

&lt;p&gt;
A second problem with the RF64 specification is that the specification is
ambiguous in a very subtle way.
The problem is with how the binary chunks within the file are specified.
For WAV files, chunks are specified in
	&lt;a href=&quot;http://www-mmsp.ece.mcgill.ca/documents/audioformats/wave/Docs/riffmci.pdf&quot;&gt;
	this document&lt;/a&gt;
as:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  typedef unsigned long DWORD ;
  typedef unsigned char BYTE ;

  typedef DWORD FOURCC ;            // Four-character code
  typedef FOURCC CKID ;             // Four-character-code chunk identifier
  typedef DWORD CKSIZE ;            // 32-bit unsigned size value

  typedef struct {                  // Chunk structure
      CKID        ckID ;                   // Chunk type identifier
      CKSIZE      ckSize ;                 // Chunk size field (size of ckData)
      BYTE        ckData [ckSize] ;        // Chunk data
  } CK;

&lt;/pre&gt;

&lt;p&gt;
This specifies that a chunk has a 4 byte identifier, followed by a 4 byte chunk
size, followed by the chunk data.
The important thing to note here is that the chunk size does not include the
4 byte chunk identifier and the 4 byte chunk size field.
Inspecting real WAV files found in the wild will confirm that this is the case
for all common chunks found in WAV files.
&lt;/p&gt;

&lt;p&gt;
Now contrast the above with how the chunks are specified in the EBU document.
Ror instance the &lt;b&gt;&lt;tt&gt;'fmt '&lt;/tt&gt;&lt;/b&gt; chunk (which is common to both WAV and
RF64) is specified as:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  struct FormatChunk5                // declare FormatChunk structure
  {
      char           chunkId[4];     // 'fmt '
      unsigned int32 chunkSize;      // 4 byte size of the 'fmt ' chunk
      unsigned int16 formatType;     // WAVE_FORMAT_PCM = 0x0001, etc.
      unsigned int16 channelCount;   // 1 = mono, 2 = stereo, etc.
      unsigned int32 sampleRate;     // 32000, 44100, 48000, etc.
      unsigned int32 bytesPerSecond; // only important for compressed formats
      unsigned int16 blockAlignment; // container size (in bytes) of one set of samples
      unsigned int16 bitsPerSample;  // valid bits per sample 16, 20 or 24
      unsigned int16 cbSize;         // extra information (after cbSize) to store
      char           extraData[22];  // extra data of WAVE_FORMAT_EXTENSIBLE when necessary
  };

&lt;/pre&gt;

&lt;p&gt;
Here, the &lt;b&gt;&lt;tt&gt;chunkSize&lt;/tt&gt;&lt;/b&gt; field is simply the &lt;i&gt;&amp;quot;size of the 'fmt '
chunk&amp;quot;&lt;/i&gt; and nowhere in the EBU document is it specified exactly how that
&lt;b&gt;&lt;tt&gt;chunkSize&lt;/tt&gt;&lt;/b&gt; field should be calculated.
However, if you give the EBU documentation to any experienced software engineer
with no previous knowledge of RIFF/WAV files, they would almost certainly assume
that the &lt;b&gt;&lt;tt&gt;chunkSize&lt;/tt&gt;&lt;/b&gt; field should be the size of the whole chunk,
including the &lt;b&gt;&lt;tt&gt;chunkID&lt;/tt&gt;&lt;/b&gt; and &lt;b&gt;&lt;tt&gt;chunkSize&lt;/tt&gt;&lt;/b&gt; fields.
However, someone who knows about RIFF/WAV files will be less likely to follow
that path.
&lt;/p&gt;

&lt;p&gt;
This leaves the programmer implementing code to read and write this format with
a couple of possibilities:
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Assume that the document is right and should be followed to the letter.
	&lt;/li&gt;
&lt;li&gt;Assume the document is wrong and that the &lt;b&gt;&lt;tt&gt;'fmt '&lt;/tt&gt;&lt;/b&gt; chunk of
	an RF64 file should be identical to that of a WAV file.
	&lt;/li&gt;
&lt;li&gt;&lt;s&gt;Give up and go home.&lt;/s&gt;
	&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
However, the last part of section 3.5 of the EBU/RF64 document describes how a
WAV file is to be upgraded to an RF64 file, and that description makes no
mention of the &lt;b&gt;&lt;tt&gt;'fmt '&lt;/tt&gt;&lt;/b&gt; chunk being modified during that upgrade.
One can only assume from this, that the &lt;b&gt;&lt;tt&gt;'fmt '&lt;/tt&gt;&lt;/b&gt; chunk in an RF64
file should be identical to that of a WAV file and that the EBU/RF64
specification is misleading.
&lt;/p&gt;

&lt;p&gt;
For libsndfile, I have decided to assume that the specification is indeed
misleading.
Unfortunately, I'm pretty sure that at some point I will be asked to at least
&lt;i&gt;read&lt;/i&gt; files which strictly adhere to the literal interpretation of the
document.
I'm also pretty sure that implementing code to read files written to conform to
both interpretations of the spec will be a very painful exercise.
&lt;/p&gt;




</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/libsndfile/rf64_specs.html</id><title type="text">The (Problems with the) RF64 File Specification.</title><updated>2010-10-07T10:36:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/libsndfile/distros_and_test_suites.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
libsndfile is cross platform and is expected to run on 32 and 64 bit CPUs on
any system that is reasonably POSIX compliant (ie even Windows).
It also has a lot of low level code that does things like endian swapping and
bit shifting etc.
Although I compile and test the code on all the systems I have access to, I
don't have access to everything.
That's why libsndfile has a test suite.
&lt;/p&gt;

&lt;p&gt;
The libsndfile test suite is as comprehensive as I can make it.
Its taken a lot or work, over man years to get to where it is, but has saved me
many times that amount of work tracking obscure bugs.
&lt;/p&gt;

&lt;p&gt;
The test suite is important.
That's why I suggest that anyone building libsndfile from source should run the
test suite before using the library.
This is especially true for people packaging libsndfile for distributions.
That's why is so disappointing to see something like this
	&lt;a href=&quot;https://bugs.gentoo.org/335728&quot;&gt;
	Gentoo bug&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
Gentoo managed to mess up their build meta-data resulting in a libsndfile binary
that was horribly broken on 32 bit systems.
It was broken in such a way that just about every single test in the libsndfile
test suite would have failed.
Unfortunately, since Gentoo didn't run the test suite they distributed their
broken build meta-data to users.
And the users started emailing me with weird bug reports.
&lt;/p&gt;

&lt;p&gt;
Fortunately, other distributions like Debian get it right.
Debian even keeps
	&lt;a href=&quot;https://buildd.debian.org/&quot;&gt;
	build logs&lt;/a&gt;
for all releases of all packages on all architectures and makes them available
on the web.
For instance, the build log for libsndfile version 1.0.21-3 on the MIPS can be
	&lt;a href=&quot;https://buildd.debian.org/fetch.cgi?&amp;amp;pkg=libsndfile&amp;amp;ver=1.0.21-3&amp;amp;arch=mips&amp;amp;stamp=1280847502&amp;amp;file=log&quot;&gt;
	found here&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
If anyone is using a distro which does not routinely run the test suite when
building packages which supply a test suite, I recommend that they switch to
a distro that does.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/libsndfile/distros_and_test_suites.html</id><title type="text">Distros and Test Suites.</title><updated>2010-10-03T11:58:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-28.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
On Thursday September 16th, we held the 28th meeting of the Sydney Functional
Programming group.
The meeting was held at Google's Sydney offices and we had a bit less than 20
people show up to hear our two presenters.
&lt;/p&gt;

&lt;p&gt;
First up we had Shane Stephens with a presentation titled
	&lt;a href=&quot;https://docs.google.com/present/edit?id=0AarxCNC60L1qZGYzNHdoOXJfNDJndmtzeDhoag&amp;amp;hl=en&quot;&gt;
	&amp;quot;Exploring 3D Graphics with Togra&amp;quot;&lt;/a&gt;.
Togra
	&lt;a href=&quot;http://github.com/shans/togra&quot;&gt;
	(code available here)&lt;/a&gt;
is a library for 3D graphics that Shane has at different times tried implementing
in Python (with C for speed), Ocaml and Haskell before settling on the use of
	&lt;a href=&quot;http://www.haskell.org/arrows/&quot;&gt;
	Arrows&lt;/a&gt;
in Haskell.
&lt;/p&gt;

&lt;p&gt;
Shane started off showing how he used to do it in Python and C and explained
that the Python/C code was difficult to maintain and contained significant chunks
of code that implemented type checking of data objects passed from Python.
He also mentioned very briefly a failed attempt to implement the library with
Monads.
With the library is not finished, or even really ready for playing with Shane
does think that Arrows are the right solution.
&lt;/p&gt;

&lt;p&gt;
Our second presenter for the evening was Anthony Sloane of Macquarie University
on the subject of the
	&lt;a href=&quot;http://code.google.com/p/kiama/wiki/Research&quot;&gt;
	&amp;quot;Launchbury's Natural Semantics for Lazy Evaluation&amp;quot;&lt;/a&gt;
with Scala code available on the same page.
Tony set up a simple language and then walked us through the reduction rules
for the language.
This was a real nice introduction to a topic that can be daunting for people
unfamiliar with the topic.
&lt;/p&gt;

&lt;p&gt;
A big thanks to Shane and Tony for presenting and Google for providing the
meeting venue and refreshments.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-28.html</id><title type="text">FP-Syd #28.</title><updated>2010-09-21T10:12:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_milestone2.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
For a couple of weeks after AusHac 2010 I didn't manage to find any time to
working on DDC at all, but I'm now back on it and late last week I  reached the
second milestone on the
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_backend.html&quot;&gt;
	LLVM backend for DDC&lt;/a&gt;.
The backend now has the ability to box and unbox 32 bit integers and perform
simple arithmetic operations on valid combinations of them.
&lt;/p&gt;

&lt;p&gt;
Disciple code that can currently be compiled correctly via LLVM includes basic
stuff like:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  identInt :: Int -&amp;gt; Int
  identInt a = a

  plusOneInt :: Int -&amp;gt; Int
  plusOneInt x = x + 1

  addInt :: Int -&amp;gt; Int -&amp;gt; Int
  addInt a b = a + b

  addInt32U :: Int32# -&amp;gt; Int32# -&amp;gt; Int32#
  addInt32U a b = a + b

  addMixedInt :: Int32# -&amp;gt; Int -&amp;gt; Int
  addMixedInt a b = boxInt32 (a + unboxInt32 b)

  cafOneInt :: Int
  cafOneInt = 1

  plusOne :: Int -&amp;gt; Int
  plusOne x = x + cafOneInt

&lt;/pre&gt;

&lt;p&gt;
where &lt;b&gt;&lt;tt&gt;Int32#&lt;/tt&gt;&lt;/b&gt; specifies an unboxed 32 bit integer and
&lt;b&gt;&lt;tt&gt;Int32&lt;/tt&gt;&lt;/b&gt; specifies the boxed version.
&lt;/p&gt;

&lt;p&gt;
While writing the Haskell code for DDC, I'm finding that its easiest to generate
LLVM code for a specific narrow case first and then generalize it as more cases
come to light.
I also found that the way I had been doing the LLVM code generation was tedious
and ugly, invloving lots of concatenation of small lists.
To fix this I built myself an &lt;b&gt;&lt;tt&gt;LlvmM&lt;/tt&gt;&lt;/b&gt; monad on top of the
&lt;b&gt;&lt;tt&gt;StateT&lt;/tt&gt;&lt;/b&gt; monad:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  type LlvmM = StateT [[LlvmStatement]] IO

&lt;/pre&gt;

&lt;p&gt;
Using this I can then generate a block of LLVM code as a list of
&lt;b&gt;&lt;tt&gt;LlvmStatement&lt;/tt&gt;&lt;/b&gt;s and add it to the monad using an
&lt;b&gt;&lt;tt&gt;addBlock&lt;/tt&gt;&lt;/b&gt; function which basically pushes the blocks of code
down onto a stack:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  addBlock :: [LlvmStatement] -&amp;gt; LlvmM ()
  addBlock code
   = do	  state	&amp;lt;- get
          put (code : state)

&lt;/pre&gt;

&lt;p&gt;
The &lt;b&gt;&lt;tt&gt;addBlock&lt;/tt&gt;&lt;/b&gt; function is then used as the base building block
for a bunch of more specific functions like these:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  unboxInt32 :: LlvmVar -&amp;gt; LlvmM LlvmVar
  unboxInt32 objptr
   | getVarType objptr == pObj
   = do     int32    &amp;lt;- lift $ newUniqueReg i32
            iptr0    &amp;lt;- lift $ newUniqueNamedReg &amp;quot;iptr0&amp;quot; (pLift i32)
            iptr1    &amp;lt;- lift $ newUniqueNamedReg &amp;quot;iptr1&amp;quot; (pLift i32)
            addBlock
                    [ Comment [ show int32 ++ &amp;quot; = unboxInt32 (&amp;quot; ++ show objptr ++ &amp;quot;)&amp;quot; ]
                    , Assignment iptr0 (GetElemPtr True objptr [llvmWordLitVar 0, i32LitVar 0])
                    , Assignment iptr1 (GetElemPtr True iptr0 [llvmWordLitVar 1])
                    , Assignment int32 (Load iptr1) ]
            return  int32


  readSlot :: Int -&amp;gt; LlvmM LlvmVar
  readSlot 0
   = do   dstreg    &amp;lt;- lift $ newUniqueNamedReg &amp;quot;slot.0&amp;quot; pObj
          addBlock  [ Comment [ show dstreg ++ &amp;quot; = readSlot 0&amp;quot; ]
                    , Assignment dstreg (Load localSlotBase) ]
          return    dstreg

  readSlot n
   | n &amp;gt; 0
   = do   dstreg    &amp;lt;- lift $ newUniqueNamedReg (&amp;quot;slot.&amp;quot; ++ show n) pObj
          r0        &amp;lt;- lift $ newUniqueReg pObj
          addBlock  [ Comment [ show dstreg ++ &amp;quot; = readSlot &amp;quot; ++ show n ]
                    , Assignment r0 (GetElemPtr True localSlotBase [llvmWordLitVar n])
                    , Assignment dstreg (Load (pVarLift r0)) ]
          return    dstreg

  readSlot n = panic stage $ &amp;quot;readSlot with slot == &amp;quot; ++ show n

&lt;/pre&gt;

&lt;p&gt;
which are finally hooked up to do things like:
&lt;/p&gt;

&lt;pre class=&quot;code&quot;&gt;

  llvmVarOfExp (XUnbox ty@TCon{} (XSlot v _ i))
   = do   objptr    &amp;lt;- readSlot i
          unboxAny (toLlvmType ty) objptr

  llvmVarOfExp (XUnbox ty@TCon{} (XForce (XSlot _ _ i)))
   = do   orig      &amp;lt;- readSlot i
          forced    &amp;lt;- forceObj orig
          unboxAny (toLlvmType ty) forced

&lt;/pre&gt;

&lt;p&gt;
When the code generation of a single function is complete it the list of
&lt;b&gt;&lt;tt&gt;LlvmStatement&lt;/tt&gt;&lt;/b&gt; blocks is then retrieved, reversed and
concatenated to produce the list of &lt;b&gt;&lt;tt&gt;LlvmStatement&lt;/tt&gt;&lt;/b&gt;s for the
function.
&lt;/p&gt;

&lt;p&gt;
With the &lt;b&gt;&lt;tt&gt;LlvmM&lt;/tt&gt;&lt;/b&gt; monad in place converting DDC's Sea AST into LLVM
code is now pretty straight forward.
Its just a matter of finding and implementing all the missing pieces.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/DDC/llvm_milestone2.html</id><title type="text">LLVM Backend for DDC : Milestone #2.</title><updated>2010-08-22T03:43:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-27.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
On Thursday August 12th, we held the 27th meeting of the Sydney Functional
Programming group.
The meeting was held at Google's Sydney offices and we had about 20 people show
up to hear our two presenters.
&lt;/p&gt;

&lt;p&gt;
First up we had
	&lt;a href=&quot;http://www.cse.unsw.edu.au/~benl/&quot;&gt;
	Ben Lippmeier&lt;/a&gt;
presenting the Haskell library
	&lt;a href=&quot;http://hackage.haskell.org/package/repa&quot;&gt;REPA&lt;/a&gt;
for doing high performance operations on regular, shape polymorphic, parallel
arrays.
Ben showed us some code for written with the REPA library.
The interesting thing about the code was that even though REPA allows parallel
execution on multiple cores, this parallel code is not vastly different from
how someone would write the code to execute on a single code.
Ben also provided some benchmarking figures comparing the multicore Haskell/REPA
code performing well against single core code written in C.
&lt;/p&gt;

&lt;p&gt;
Our second presenter for the evening was Simon Winwood who presented on the
subject of the
	&lt;a href=&quot;http://www.haskell.org/haskellwiki/Template_Haskell&quot;&gt;
	Template Haskell&lt;/a&gt;,
which allows type safe, compile time meta programming.
The need for templating in a powerful and flexible language like Haskell is
obviously much less than in languages like C++, but still useful for some tasks
like
	&lt;a href=&quot;http://www.haskell.org/ghc/docs/6.12.2/html/users_guide/template-haskell.html#th-quasiquotation&quot;&gt;
	quasi-quotation&lt;/a&gt;.
The mechanics of TH as such that it allows conversion between Haskell's concrete
syntax and abstract syntax trees which can be manipulated by Haskell code.
One downside of TH is that code relying on regularly breaks when new versions
of the GHC compiler are released.
&lt;/p&gt;

&lt;p&gt;
A big thanks to Ben and Simon for presenting and Google for providing the
meeting venue and refreshments.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-27.html</id><title type="text">FP-Syd #27.</title><updated>2010-08-21T13:05:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/Geany/gedit_geany.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
After effectively
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/CodeHacking/rip_nedit.html&quot;&gt;
	giving up on Nedit&lt;/a&gt;,
my text editor of choice for the last fifteen years, I gave Gedit a serious try.
&lt;/p&gt;

&lt;p&gt;
For a full two weeks, I stuck with Gedit, including the intense 2&amp;frac12; day
hacking session of
	&lt;a href=&quot;http://random.axman6.com/blog/?p=219&quot;&gt;
	AusHac2010&lt;/a&gt;.
Unfortunately, switching from a very full featured editor like Nedit to Gedit
was painful.
There were a bunch of features that I had grown used to that were just absent or
inconvienient in Gedit.
The problem is that Gedit aims to be a relatively full featured programmer's
editor while still being the default easy-to-use editor in GNOME.
As far as I am concerned, these two aims are in conflict, making Gedit an
adequate simple text editor and a poor editor for advanced coders.
&lt;/p&gt;

&lt;p&gt;
After butting my head against basic usability issues with Gedit I was even
considered either modifying it extensively using plugins or maybe even forking
it and maintaining a forked version.
Yes, that would be a huge pain in the neck, but fortunately that will not now
be necessary.
&lt;/p&gt;

&lt;p&gt;
In response to my blog post titled
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/CodeHacking/rip_nedit.html&quot;&gt;
	&lt;i&gt;&amp;quot;R.I.P. Nedit&amp;quot;&lt;/i&gt;&lt;/a&gt;
fellow Haskell hacker and Debian Haskell Group member
	&lt;a href=&quot;https://www.joachim-breitner.de/blog/&quot;&gt;
	Joachim Breitner&lt;/a&gt;
suggested I have a look at the
	&lt;a href=&quot;http://www.geany.org/&quot;&gt;
	Geany text editor and IDE&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
Geany is obviously a tool aimed squarely as an editor for full time, committed
programmers.
Its also much more than just an editor, in that it has many features of an IDE
(Integrated Development Environment).
In fact, when I first fired it up it looked like this (click for a larger view):
&lt;/p&gt;

&lt;br/&gt;
&lt;center&gt;
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Img/geany-default.png&quot;&gt;
	&lt;img src=&quot;http://www.mega-nerd.com/erikd/Img/geany-default-small.png&quot; border=&quot;0&quot; alt=&quot;Geany default window&quot;/&gt;
	&lt;/a&gt;
&lt;/center&gt;
&lt;br/&gt;

&lt;p&gt;
On seeing this I initially thought Geany was not for me.
Fortunately I found that the extra IDE-like features can easily be hidden,
providing me with a simple-to-use, highly configurable, advanced text editor.
The features I really like are:
&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;High degree of configurability, including key bindings.
		&lt;/li&gt;
	&lt;li&gt;Syntax highlighting (configurable) for a huge number of languages.
		&lt;/li&gt;
	&lt;li&gt;Custom syntax highlighting (ie user definable highlighting for languages
		not currently supported by Geany).
		&lt;/li&gt;
	&lt;li&gt;Regex search and search/replace.
		&lt;/li&gt;
	&lt;li&gt;Search and replace within a selected area only.
		&lt;/li&gt;
	&lt;li&gt;Highlighting of matching braces and brackets.
		&lt;/li&gt;
	&lt;li&gt;Language specific editing modes and auto indentation.
		&lt;/li&gt;
	&lt;li&gt;Go to specified line number.
		&lt;/li&gt;
	&lt;li&gt;Plugins.
		&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
There are still a few little niggles, but nothing like the pain I experienced
trying to use Gedit.
For instance, when run from the command line, Geany will open new files in a
tab of an existing Geany instance.
With multiple desktop workspaces, this is sub optimal.
It would be much nicer if Geany would start a new instance if there was not
already an instance running on the current workspace.
After a brief inspection of the Gedit sources (Gedit has the desired feature),
I came up with a fix for this issue which I will be submitting to the Geany
development mailing list after a couple of days of testing.
&lt;/p&gt;

&lt;p&gt;
Another minor issue (shared with Gedit) is that of fonts.
Nedit uses bitmap fonts while Geany (and Gedit) use TrueType fonts.
When I choose light coloured fonts on a black background I find the fonts in
Geany (and Gedit) a lot fuzzier than the same size fonts in Nedit.
I've tried a number of different fonts including
	&lt;a href=&quot;http://www.levien.com/type/myfonts/inconsolata.html&quot;&gt;
	Inconsolata&lt;/a&gt;
but I've currently settled on
	&lt;a href=&quot;http://dejavu-fonts.org/wiki/Main_Page&quot;&gt;
	DejaVu Sans Mono&lt;/a&gt;
although I'm not entirely satisfied.
&lt;/p&gt;

&lt;p&gt;
Currently my Geany setup (editing some Haskell code) looks like this:
&lt;/p&gt;

&lt;br/&gt;
&lt;center&gt;
	&lt;img src=&quot;http://www.mega-nerd.com/erikd/Img/geany-modded.png&quot; border=&quot;0&quot; alt=&quot;Geany modified config&quot;/&gt;
&lt;/center&gt;
&lt;br/&gt;

&lt;p&gt;
Light text on a black background with highlighting using a small number of
colours; red for types, green for literals, yellow for keywords etc.
&lt;/p&gt;

&lt;p&gt;
Geany is a great text editor.
For any committed coders currently using either Nedit or Gedit and not entirely
happy, I strongly recommend that you give Geany a try.
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/Geany/gedit_geany.html</id><title type="text">From Gedit to Geany.</title><updated>2010-08-04T11:17:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/CodeHacking/rip_nedit.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
For serious programmers, the text editor they user is an intensely personal
thing.
Try suggesting to an Emacs user that they should switch to Vim or vice-versa.
Most would shudder at the thought.
&lt;/p&gt;

&lt;p&gt;
My choice of editor for the last 15 years has been Nedit, the
	&lt;a href=&quot;http://www.nedit.org/&quot;&gt;
	Nirvana Editor&lt;/a&gt;.
Nedit has been an outstanding editor; feature full yet easy to use.
When I first started using it, Nedit was a closed source binary-only download
but sometime in the late 1990s, it was released under the GNU GPL.
&lt;/p&gt;

&lt;p&gt;
Unfortunately Nedit has been suffering from bit rot and neglect for a number
of years.
The main problem is that it uses the
	&lt;a href=&quot;http://en.wikipedia.org/wiki/Motif_(widget_toolkit)&quot;&gt;
	Motif widget toolkit&lt;/a&gt;.
For open source, there are basically two options for Motif;
	&lt;a href=&quot;http://lesstif.sourceforge.net/&quot;&gt;
	Lesstif&lt;/a&gt;,
an LGPL reimplementation of Motif which has been basically unmaintained for
a number of years, or
	&lt;a href=&quot;http://www.opengroup.org/openmotif/&quot;&gt;
	OpenMotif&lt;/a&gt;
released under a license which is in no way
	&lt;a href=&quot;http://www.opensource.org/&quot;&gt;
	OSI approved&lt;/a&gt;.
On top of that, Nedit still doesn't support UTF-8, mainly because Lesstif
doesn't support it.
&lt;/p&gt;

&lt;p&gt;
I have, in the past, tried to fix bugs in Nedit, but the bugs are not really
in Nedit itself, but in an interaction between Nedit whichever Motif library
it is linked against and the underlying X libraries.
Depending on whether Nedit is linked against Lesstif and OpenMotif, Nedit will
display different sets of bugs.
I have tried fixing bugs in Nedit linked against Lesstif, but got absolutely
nowhere.
Lesstif is one of the few code bases I have ever worked on that I was
completely unable to make progress on.
&lt;/p&gt;

&lt;p&gt;
With Nedit getting flakier with each passing year I finally decided to switch
to a new editor.
I had already discounted Emacs and Vim; switching from Nedit to either of those
two archaic beasts was going to be way too painful.
Of all the FOSS editors available,
	&lt;a href=&quot;http://projects.gnome.org/gedit/&quot;&gt;
	Gedit&lt;/a&gt;
seemed to be the closest in features to Nedit.
&lt;/p&gt;

&lt;p&gt;
Unfortunately, Gedit does not compare well with Nedit feature wise.
To me it seems to try to be simultaneously as simple as possible and to have as
many features as possible and the features don't seem to fit together all that
well from a usability point of view.
On top of that, it lacks the following:
&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Regex search and regex search/replace.
		Apparently there is a regex search/replace plugin, but that uses a
		different hot key combination that literal search/repalce.
		Nedit on the other hand uses the same dialog box for literal and
		regex search/replaces; with a toggle button to switch between literal
		and regex searches. 
		&lt;/li&gt;
	&lt;li&gt;Search and replace within the selected area only.
		&lt;/li&gt;
	&lt;li&gt;Highlighting of matching braces and brackets.
		&lt;/li&gt;
	&lt;li&gt;Language specific editing modes and auto indentation.
		&lt;/li&gt;
	&lt;li&gt;A macro language allowing further customisation.
		&lt;/li&gt;
	&lt;li&gt;A simple, quick way to go to a particular line number (for Gedit,
		Control-L is supposed to work, but doesn't).
		&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
On top of that Gedit could also do with some improved key bindings and some
improvements to its syntax highlighting patterns.
The Ocaml syntax highlighting is particularly poor.
&lt;/p&gt;

&lt;p&gt;
I'm now going to try to use Gedit, by customising its setup and and using the
plugin system to see if I can regain the features that made Nedit such a
pleasure to use.
&lt;/p&gt;





</content><id>http://www.mega-nerd.com/erikd/Blog/CodeHacking/rip_nedit.html</id><title type="text">R.I.P. Nedit</title><updated>2010-07-27T12:18:00-00:00</updated><author><name>mega-nerd</name></author></entry><entry><link href="http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-26.html" rel="alternate"/><contributor><uri>http://www.mega-nerd.com/erikd/Blog/index.rss20</uri><name>mega-nerd</name></contributor><content type="html">

&lt;p&gt;
On Thursday July 15th, we held the 26th meeting of the Sydney Functional
Programming group.
The meeting was held at Google's Sydney offices and we had 18 people show up
to hear our two presenters.
&lt;/p&gt;

&lt;p&gt;
First up we had your correspondent
	&lt;a href=&quot;http://www.mega-nerd.com/erikd/Blog/&quot;&gt;
	(thats me)&lt;/a&gt;
with a presentation titled
	&lt;a href=&quot;http://fp-syd.googlegroups.com/web/ddc-llvm.pdf&quot;&gt;
	An LLVM Backend for DDC&lt;/a&gt;.
This presentation covered the problems with the current C backend, gave
a description of LLVM, the options for using LLVM from Haskell, why the LLVM
code from GHC was chosen and how if fits into the DDC compile pipeline.
Finally I demoed the very wonderful
	&lt;a href=&quot;http://llvm.org/demo/index.cgi&quot;&gt;
	LLVM CGI script&lt;/a&gt;
which allows you to enter a small C program and view the LLVM output.
&lt;/p&gt;

&lt;p&gt;
Our second presenter for the evening was Eric Willigers who presented on the
subject of the
	&lt;a href=&quot;http://www.ats-lang.org/&quot;&gt;
	ATS programming langauge&lt;/a&gt;.
ATS is interesting because it offers functional programming with an advanced
type system with things like
	&lt;a href=&quot;http://en.wikipedia.org/wiki/Dependent_type&quot;&gt;
	dependent types&lt;/a&gt;
and 
	&lt;a href=&quot;http://en.wikipedia.org/wiki/Linear_type_system&quot;&gt;
	linear types&lt;/a&gt;
but has excellent performance as shown on the
	&lt;a href=&quot;http://shootout.alioth.debian.org/u64/benchmark.php?test=all&amp;amp;lang=ats&quot;&gt;
	Computer Language Benchmarks Game&lt;/a&gt;.
Eric was able to demonstrate dependent types on a couple of list operations
which certainly showed some of the promise of dependent types.
ATS certainly does seem interesting but also seems to lack quite a bit of
polish.
&lt;/p&gt;

&lt;p&gt;
A big thanks to Eric for presenting and Google for providing the meeting venue
and refreshments. 
&lt;/p&gt;


</content><id>http://www.mega-nerd.com/erikd/Blog/FP-Syd/fp-syd-26.html</id><title type="text">FP-Syd #26.</title><updated>2010-07-25T12:11:00-00:00</updated><author><name>mega-nerd</name></author></entry></feed>