---
title: The Uncertain Art of Accelerating ML Models with Sylvain Gugger
description:
url: https://signals-threads.simplecast.com/episodes/the-uncertain-art-of-accelerating-ml-models-with-sylvain-gugger-moYuL4Ps
date: 2024-10-14T14:47:42-00:00
preview_image:
authors:
- Signals and Threads
source:
---

<p>Sylvain Gugger is a former math teacher who fell into machine learning via a MOOC and became an expert in the low-level performance details of neural networks. He’s now on the ML infrastructure team at Jane Street, where he helps traders speed up their models. In this episode, Sylvain and Ron go deep on learning rate schedules; the subtle performance bugs PyTorch lets you write; how to keep a hungry GPU well-fed; and lots more, including the foremost importance of reproducibility in training runs. They also discuss some of the unique challenges of doing ML in the world of trading, like the unusual size and shape of market data and the need to do inference at shockingly low latencies.</p><p>You can find the transcript for this episode &nbsp;on our <a href="https://signalsandthreads.com/the-uncertain-art-of-accelerating-ml-models" target="_blank">website</a>.</p><p>Some links to topics that came up in the discussion:</p><ul><li><a href="https://course.fast.ai/">“Practical Deep Learning for Coders,”</a> a FastAI MOOC by Jeremy Howard, and the <a href="https://fastai.github.io/fastbook2e/">book</a>, of which Sylvain is a co-author.</li><li>The <a href="https://dawn.cs.stanford.edu/benchmark/#cifar10-train-cost">Stanford DAWNBench</a> competition that Sylvain participated in.</li><li><a href="https://huggingface.co/">HuggingFace</a>, and the <a href="https://huggingface.co/docs/accelerate/en/index">Accelerate library</a> that Sylvain wrote there.</li><li>Some of the languages/systems for expression ML models that were discussed: <a href="https://pytorch.org/">PyTorch</a>, <a href="https://www.tensorflow.org/">TensorFlow</a>, <a href="https://github.com/jax-ml/jax">Jax</a>, <a href="https://www.modular.com/mojo">Mojo</a>, and <a href="https://triton-lang.org/main/index.html">Triton</a></li><li>CUDA <a href="https://developer.nvidia.com/blog/cuda-graphs/">graphs</a> and <a href="https://developer.download.nvidia.com/CUDA/training/StreamsAndConcurrencyWebinar.pdf">streams</a></li><li><a href="https://people.eecs.berkeley.edu/~brecht/papers/hogwildTR.pdf">Hogwild concurrency</a></li></ul>

